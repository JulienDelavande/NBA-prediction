{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './../data/nba_logreg.csv'\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Ingram</td>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Harrison</td>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaKarr Sampson</td>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik Sealy</td>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Geiger</td>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  GP   MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  ...  \\\n",
       "0   Brandon Ingram  36  27.4  7.4  2.6  7.6  34.7      0.5  2.1  25.0  ...   \n",
       "1  Andrew Harrison  35  26.9  7.2  2.0  6.7  29.6      0.7  2.8  23.5  ...   \n",
       "2   JaKarr Sampson  74  15.3  5.2  2.0  4.7  42.2      0.4  1.7  24.4  ...   \n",
       "3      Malik Sealy  58  11.6  5.7  2.3  5.5  42.6      0.1  0.5  22.6  ...   \n",
       "4      Matt Geiger  48  11.5  4.5  1.6  3.0  52.4      0.0  0.1   0.0  ...   \n",
       "\n",
       "   FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0  2.3  69.9   0.7   3.4  4.1  1.9  0.4  0.4  1.3          0.0  \n",
       "1  3.4  76.5   0.5   2.0  2.4  3.7  1.1  0.5  1.6          0.0  \n",
       "2  1.3  67.0   0.5   1.7  2.2  1.0  0.5  0.3  1.0          0.0  \n",
       "3  1.3  68.9   1.0   0.9  1.9  0.8  0.6  0.1  1.0          1.0  \n",
       "4  1.9  67.4   1.0   1.5  2.5  0.3  0.3  0.4  0.8          1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA',\n",
      "       '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK',\n",
      "       'TOV', 'TARGET_5Yrs'],\n",
      "      dtype='object')\n",
      "                GP          MIN          PTS          FGM          FGA  \\\n",
      "count  1340.000000  1340.000000  1340.000000  1340.000000  1340.000000   \n",
      "mean     60.414179    17.624627     6.801493     2.629104     5.885299   \n",
      "std      17.433992     8.307964     4.357545     1.683555     3.593488   \n",
      "min      11.000000     3.100000     0.700000     0.300000     0.800000   \n",
      "25%      47.000000    10.875000     3.700000     1.400000     3.300000   \n",
      "50%      63.000000    16.100000     5.550000     2.100000     4.800000   \n",
      "75%      77.000000    22.900000     8.800000     3.400000     7.500000   \n",
      "max      82.000000    40.900000    28.200000    10.200000    19.800000   \n",
      "\n",
      "               FG%      3P Made          3PA          3P%          FTM  \\\n",
      "count  1340.000000  1340.000000  1340.000000  1329.000000  1340.000000   \n",
      "mean     44.169403     0.247612     0.779179    19.308126     1.297687   \n",
      "std       6.137679     0.383688     1.061847    16.022916     0.987246   \n",
      "min      23.800000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%      40.200000     0.000000     0.000000     0.000000     0.600000   \n",
      "50%      44.100000     0.100000     0.300000    22.400000     1.000000   \n",
      "75%      47.900000     0.400000     1.200000    32.500000     1.600000   \n",
      "max      73.700000     2.300000     6.500000   100.000000     7.700000   \n",
      "\n",
      "               FTA          FT%         OREB         DREB          REB  \\\n",
      "count  1340.000000  1340.000000  1340.000000  1340.000000  1340.000000   \n",
      "mean      1.821940    70.300299     1.009403     2.025746     3.034478   \n",
      "std       1.322984    10.578479     0.777119     1.360008     2.057774   \n",
      "min       0.000000     0.000000     0.000000     0.200000     0.300000   \n",
      "25%       0.900000    64.700000     0.400000     1.000000     1.500000   \n",
      "50%       1.500000    71.250000     0.800000     1.700000     2.500000   \n",
      "75%       2.300000    77.600000     1.400000     2.600000     4.000000   \n",
      "max      10.200000   100.000000     5.300000     9.600000    13.900000   \n",
      "\n",
      "               AST          STL          BLK          TOV  TARGET_5Yrs  \n",
      "count  1340.000000  1340.000000  1340.000000  1340.000000  1340.000000  \n",
      "mean      1.550522     0.618507     0.368582     1.193582     0.620149  \n",
      "std       1.471169     0.409759     0.429049     0.722541     0.485531  \n",
      "min       0.000000     0.000000     0.000000     0.100000     0.000000  \n",
      "25%       0.600000     0.300000     0.100000     0.700000     0.000000  \n",
      "50%       1.100000     0.500000     0.200000     1.000000     1.000000  \n",
      "75%       2.000000     0.800000     0.500000     1.500000     1.000000  \n",
      "max      10.600000     2.500000     3.900000     4.400000     1.000000  \n",
      "Name            0\n",
      "GP              0\n",
      "MIN             0\n",
      "PTS             0\n",
      "FGM             0\n",
      "FGA             0\n",
      "FG%             0\n",
      "3P Made         0\n",
      "3PA             0\n",
      "3P%            11\n",
      "FTM             0\n",
      "FTA             0\n",
      "FT%             0\n",
      "OREB            0\n",
      "DREB            0\n",
      "REB             0\n",
      "AST             0\n",
      "STL             0\n",
      "BLK             0\n",
      "TOV             0\n",
      "TARGET_5Yrs     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n",
    "print(data.describe())\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Ken Johnson</td>\n",
       "      <td>64</td>\n",
       "      <td>12.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>52.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>43.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Ken Johnson</td>\n",
       "      <td>64</td>\n",
       "      <td>12.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>52.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>43.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Pete Williams</td>\n",
       "      <td>53</td>\n",
       "      <td>10.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>60.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>42.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Melvin Turpin</td>\n",
       "      <td>79</td>\n",
       "      <td>24.7</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>78.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Jim Petersen</td>\n",
       "      <td>60</td>\n",
       "      <td>11.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>48.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>75.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Tom Scheffler</td>\n",
       "      <td>39</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>41.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Sam Williams</td>\n",
       "      <td>59</td>\n",
       "      <td>18.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>55.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>55.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Kurt Nimphius</td>\n",
       "      <td>63</td>\n",
       "      <td>17.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>58.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Pete Verhoeven</td>\n",
       "      <td>71</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>50.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>Jim Smith</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>50.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>Jeff Wilkins</td>\n",
       "      <td>56</td>\n",
       "      <td>18.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>67.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA  3P%  ...  \\\n",
       "338     Ken Johnson  64  12.7   4.1  1.8  3.3  52.8      0.0  0.0  NaN  ...   \n",
       "339     Ken Johnson  64  12.7   4.1  1.8  3.3  52.8      0.0  0.0  NaN  ...   \n",
       "340   Pete Williams  53  10.8   2.8  1.3  2.1  60.4      0.0  0.0  NaN  ...   \n",
       "358   Melvin Turpin  79  24.7  10.6  4.6  9.0  51.1      0.0  0.0  NaN  ...   \n",
       "386    Jim Petersen  60  11.9   3.2  1.2  2.4  48.6      0.0  0.0  NaN  ...   \n",
       "397   Tom Scheffler  39   6.9   1.3  0.5  1.3  41.2      0.0  0.0  NaN  ...   \n",
       "507    Sam Williams  59  18.2   6.1  2.6  4.7  55.6      0.0  0.0  NaN  ...   \n",
       "509   Kurt Nimphius  63  17.2   5.3  2.2  4.7  46.1      0.0  0.0  NaN  ...   \n",
       "510  Pete Verhoeven  71  17.0   4.9  2.1  4.2  50.3      0.0  0.0  NaN  ...   \n",
       "521       Jim Smith  72  11.9   2.9  1.2  2.3  50.9      0.0  0.0  NaN  ...   \n",
       "559    Jeff Wilkins  56  18.9   4.7  2.1  4.6  45.0      0.0  0.0  NaN  ...   \n",
       "\n",
       "     FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "338  1.3  43.5   1.4   2.4  3.8  0.3  0.2  0.3  0.9          0.0  \n",
       "339  1.3  43.5   1.4   2.4  3.8  0.3  0.2  0.3  0.9          0.0  \n",
       "340  0.8  42.5   0.9   1.9  2.8  0.3  0.4  0.4  0.4          0.0  \n",
       "358  1.8  78.4   2.0   3.8  5.7  0.5  0.5  1.1  1.5          1.0  \n",
       "386  1.1  75.8   0.7   1.7  2.5  0.5  0.2  0.5  1.2          1.0  \n",
       "397  0.5  50.0   0.5   1.5  1.9  0.3  0.2  0.3  0.4          0.0  \n",
       "507  1.5  55.1   1.5   3.7  5.2  0.6  0.8  1.3  1.1          0.0  \n",
       "509  1.7  58.3   1.5   3.2  4.7  1.0  0.3  1.3  0.9          1.0  \n",
       "510  1.0  70.8   1.5   2.1  3.6  0.7  0.6  0.3  0.8          1.0  \n",
       "521  1.2  45.9   1.0   1.5  2.5  0.6  0.3  0.7  0.7          0.0  \n",
       "559  0.7  67.5   1.1   3.8  4.9  0.7  0.6  0.8  1.1          1.0  \n",
       "\n",
       "[11 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['3P%'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate 11 valeurs nulles dans la colonne 3P% qui correespondent aux joueurs qui n'ont pas tiré à 3 points. On va donc remplacer ces valeurs par 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x='TARGET_5Yrs', data=data)\n",
    "plt.title('Distribution of TARGET_5Yrs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate un data set déséquilibré, rééquilibrer le data set sera envisagé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Charles Jones</td>\n",
       "      <td>78</td>\n",
       "      <td>20.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>64.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Charles Jones</td>\n",
       "      <td>29</td>\n",
       "      <td>16.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>31.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>31.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Charles Smith</td>\n",
       "      <td>60</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>44.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>69.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Charles Smith</td>\n",
       "      <td>71</td>\n",
       "      <td>30.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>49.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Charles Smith</td>\n",
       "      <td>34</td>\n",
       "      <td>8.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>31.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>Chris Smith</td>\n",
       "      <td>80</td>\n",
       "      <td>15.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>79.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Eddie Johnson</td>\n",
       "      <td>74</td>\n",
       "      <td>20.5</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>Gerald Henderson</td>\n",
       "      <td>43</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>21.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Ken Johnson</td>\n",
       "      <td>64</td>\n",
       "      <td>12.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>52.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>43.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>Marcus Williams</td>\n",
       "      <td>79</td>\n",
       "      <td>16.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>28.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>84.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Mike Dunleavy</td>\n",
       "      <td>82</td>\n",
       "      <td>15.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>34.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Reggie Williams</td>\n",
       "      <td>35</td>\n",
       "      <td>24.5</td>\n",
       "      <td>10.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>22.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>72.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name  GP   MIN   PTS  FGM   FGA   FG%  3P Made  3PA   3P%  \\\n",
       "366      Charles Jones  78  20.1   8.4  3.0   5.8  52.0      0.0  0.1   0.0   \n",
       "369      Charles Jones  29  16.4   3.7  1.3   4.2  31.7      0.7  2.1  31.1   \n",
       "163      Charles Smith  60   8.7   2.9  1.0   2.2  44.4      0.0  0.1   0.0   \n",
       "166      Charles Smith  71  30.4  16.3  6.1  12.4  49.5      0.0  0.0   0.0   \n",
       "169      Charles Smith  34   8.6   3.5  1.4   3.7  39.2      0.4  1.4  31.9   \n",
       "1335       Chris Smith  80  15.8   4.3  1.6   3.6  43.3      0.0  0.2  14.3   \n",
       "504      Eddie Johnson  74  20.5   9.3  4.0   8.7  45.9      0.0  0.1   9.1   \n",
       "733   Gerald Henderson  43   8.3   2.6  0.9   2.4  35.6      0.1  0.4  21.1   \n",
       "339        Ken Johnson  64  12.7   4.1  1.8   3.3  52.8      0.0  0.0   NaN   \n",
       "824    Marcus Williams  79  16.6   6.8  2.6   6.7  39.5      0.6  2.1  28.2   \n",
       "971      Mike Dunleavy  82  15.9   5.7  2.0   5.1  40.3      0.6  1.8  34.7   \n",
       "243    Reggie Williams  35  24.5  10.4  4.3  12.2  35.6      0.4  1.7  22.4   \n",
       "\n",
       "      ...  FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "366   ...  3.6  64.8   1.8   3.3  5.1  1.6  0.6  0.8  1.8          0.0  \n",
       "369   ...  0.8  50.0   0.3   1.1  1.4  1.4  0.6  0.2  1.0          0.0  \n",
       "163   ...  1.3  69.7   0.2   0.9  1.2  1.7  0.6  0.1  0.6          1.0  \n",
       "166   ...  5.5  72.5   2.4   4.1  6.5  1.5  1.0  1.3  2.1          1.0  \n",
       "169   ...  0.3  54.5   0.4   0.4  0.8  0.6  0.3  0.2  0.8          1.0  \n",
       "1335  ...  1.5  79.2   0.4   0.8  1.2  2.5  0.6  0.2  0.8          0.0  \n",
       "504   ...  2.0  66.4   1.7   2.6  4.4  1.5  0.7  0.2  1.3          1.0  \n",
       "733   ...  1.1  74.5   0.3   0.9  1.3  0.3  0.2  0.2  0.3          1.0  \n",
       "339   ...  1.3  43.5   1.4   2.4  3.8  0.3  0.2  0.3  0.9          0.0  \n",
       "824   ...  1.1  84.7   0.4   1.7  2.1  3.3  0.4  0.0  1.8          0.0  \n",
       "971   ...  1.2  78.0   0.8   1.8  2.6  1.3  0.7  0.2  1.1          1.0  \n",
       "243   ...  1.9  72.7   1.6   1.8  3.4  1.7  0.8  0.6  1.8          1.0  \n",
       "\n",
       "[12 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated()].sort_values(by='Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe des lignes en double."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Outlayers detection for all columns\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(data=data)\n",
    "plt.title('Outlayers detection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DuplicateRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, method='DROP_SAME_ROWS'):\n",
    "        self.method = method\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.method == 'DROP_SAME_ROWS':\n",
    "            X = X.drop_duplicates()\n",
    "        elif self.method == 'NONE':\n",
    "            pass\n",
    "        return X\n",
    "\n",
    "\n",
    "class NullValueReplacer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=['3P%'], values=[0]):\n",
    "        self.columns = columns\n",
    "        self.values = values\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for i in range(len(self.columns)):\n",
    "            column = self.columns[i]\n",
    "            if self.values[i] == 'MEDIAN':\n",
    "                X.loc[:, column] = X.loc[:, column].fillna(X[column].median())\n",
    "            elif self.values[i] == 'MEAN':\n",
    "                X.loc[:, column] = X.loc[:, column].fillna(X[column].mean())\n",
    "            elif self.values[i] == 'MODE':\n",
    "                X.loc[:, column] = X.loc[:, column].fillna(X[column].mode()[0])\n",
    "            else:\n",
    "                X.loc[:, column] = X.loc[:, column].fillna(self.values[i])\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "class DataBalancer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target='TARGET_5Yrs', method='OVERSAMPLING'):\n",
    "        self.target = target\n",
    "        self.method = method\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.method == 'OVERSAMPLING':\n",
    "            data_0 = X[X[self.target] == 0]\n",
    "            data_1 = X[X[self.target] == 1]\n",
    "            data_0 = data_0.sample(data_1.shape[0], replace=True)\n",
    "            X = pd.concat([data_0, data_1], axis=0)\n",
    "        elif self.method == 'UNDERSAMPLING':\n",
    "            data_0 = X[X[self.target] == 0]\n",
    "            data_1 = X[X[self.target] == 1]\n",
    "            data_1 = data_1.sample(data_0.shape[0], replace=True)\n",
    "            X = pd.concat([data_0, data_1], axis=0)\n",
    "        elif self.method == 'SMOTE':\n",
    "            smote = SMOTE(random_state=42)\n",
    "            y = X[self.target]\n",
    "            X = X.drop(self.target, axis=1)\n",
    "            X, y = smote.fit_resample(X, y)\n",
    "            X = pd.concat([X, y], axis=1)\n",
    "        elif self.method == 'NONE':\n",
    "            pass\n",
    "        else:\n",
    "            print('No method selected')\n",
    "        return X.reset_index(drop=True)\n",
    "\n",
    "\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.feature_names]\n",
    "    \n",
    "class FeatureScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        scaler = MinMaxScaler()\n",
    "        X[self.feature_names] = scaler.fit_transform(X[self.feature_names])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(data, target='TARGET_5Yrs', method='corr', threshold=0.1):\n",
    "    if method == 'corr':\n",
    "        corr = data.corr()\n",
    "        corr = corr[target].sort_values(ascending=False)\n",
    "        corr = corr[abs(corr) > threshold]\n",
    "        data = data[corr.index]\n",
    "    elif method == 'rf':\n",
    "        X = data.drop(target, axis=1)\n",
    "        y = data[target]\n",
    "        rf = RandomForestClassifier()\n",
    "        rf.fit(X, y)\n",
    "        importances = rf.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        columns = X.columns\n",
    "        for i in indices:\n",
    "            if importances[i] > threshold:\n",
    "                print(columns[i], ':', importances[i])\n",
    "        data = data[X.columns[indices]]\n",
    "    else:\n",
    "        print('No method selected')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "\n",
    "def score_classifier(dataset,classifier,labels, folds=3):\n",
    "\n",
    "    \"\"\"\n",
    "    performs 3 random trainings/tests to build a confusion matrix and prints results with precision and recall scores\n",
    "    :param dataset: the dataset to work on\n",
    "    :param classifier: the classifier to use\n",
    "    :param labels: the labels used for training and validation\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    kf = KFold(n_splits=folds,random_state=50,shuffle=True)\n",
    "    confusion_mat_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    accuracy_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for training_ids,test_ids in kf.split(dataset):\n",
    "        training_set = dataset.iloc[training_ids]\n",
    "        training_labels = labels.iloc[training_ids]\n",
    "        test_set = dataset.iloc[test_ids]\n",
    "        test_labels = labels.iloc[test_ids]\n",
    "        classifier.fit(training_set,training_labels)\n",
    "        predicted_labels = classifier.predict(test_set)\n",
    "\n",
    "        confusion_mat = confusion_matrix(test_labels,predicted_labels)\n",
    "        recall = recall_score(test_labels, predicted_labels)\n",
    "        precision = precision_score(test_labels, predicted_labels)\n",
    "        accuracy = classifier.score(test_set, test_labels)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n",
    "        accuracy_list.append(accuracy)\n",
    "        f1_list.append(f1)\n",
    "        confusion_mat_list.append(confusion_mat)\n",
    "\n",
    "    recall = np.mean(recall_list)\n",
    "    precision = np.mean(precision_list)\n",
    "    accuracy = np.mean(accuracy_list)\n",
    "    f1 = np.mean(f1_list)\n",
    "    confusion_mat = np.mean(confusion_mat_list,axis=0).astype(int)\n",
    "\n",
    "    print(f\"confusion_mat: \\n {confusion_mat}\")\n",
    "    print(f\"recall:{recall}\")\n",
    "    print(f\"precision:{precision}\")\n",
    "    print(f\"accuracy:{accuracy}\")\n",
    "    print(f\"f1:{f1}\")\n",
    "    return {'confusion_mat':confusion_mat,'recall':recall,'precision':precision,'accuracy':accuracy,'f1':f1, 'classifier':classifier}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression()\n",
      "confusion_mat: \n",
      " [[ 88  80]\n",
      " [ 47 227]]\n",
      "recall:0.8271461152756118\n",
      "precision:0.7392574577642866\n",
      "accuracy:0.7123428291267887\n",
      "f1:0.7806680335496549\n",
      "\n",
      "Model: RandomForestClassifier()\n",
      "confusion_mat: \n",
      " [[ 90  78]\n",
      " [ 59 215]]\n",
      "recall:0.7846355083765156\n",
      "precision:0.7338785634052166\n",
      "accuracy:0.6905031851254133\n",
      "f1:0.7583440254194862\n",
      "\n",
      "Model: SVC()\n",
      "confusion_mat: \n",
      " [[ 90  78]\n",
      " [ 47 227]]\n",
      "recall:0.8274446177323874\n",
      "precision:0.7441701832638451\n",
      "accuracy:0.7168575018130191\n",
      "f1:0.7835325512158953\n",
      "\n",
      "Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "confusion_mat: \n",
      " [[ 86  81]\n",
      " [ 63 211]]\n",
      "recall:0.7696324059633413\n",
      "precision:0.7207515991049757\n",
      "accuracy:0.6731662972534038\n",
      "f1:0.7443439339517157\n",
      "\n",
      "Model: KNeighborsClassifier()\n",
      "confusion_mat: \n",
      " [[ 90  77]\n",
      " [ 64 210]]\n",
      "recall:0.7668528114571279\n",
      "precision:0.7313501343706875\n",
      "accuracy:0.6807213943052478\n",
      "f1:0.7484269401911009\n",
      "\n",
      "Model: DecisionTreeClassifier()\n",
      "confusion_mat: \n",
      " [[ 84  84]\n",
      " [ 90 184]]\n",
      "recall:0.6726224614713824\n",
      "precision:0.6877151658750171\n",
      "accuracy:0.6069187529153005\n",
      "f1:0.6796078569548049\n",
      "\n",
      "Model: GradientBoostingClassifier()\n",
      "confusion_mat: \n",
      " [[ 88  79]\n",
      " [ 58 216]]\n",
      "recall:0.7887642333685498\n",
      "precision:0.7317601783605153\n",
      "accuracy:0.6897507396777082\n",
      "f1:0.759085772984078\n",
      "\n",
      "Model: AdaBoostClassifier()\n",
      "confusion_mat: \n",
      " [[ 90  78]\n",
      " [ 67 207]]\n",
      "recall:0.7547282453757274\n",
      "precision:0.7264560887041149\n",
      "accuracy:0.6716835371064557\n",
      "f1:0.7401812908228363\n",
      "\n",
      "Model: ExtraTreesClassifier()\n",
      "confusion_mat: \n",
      " [[ 91  76]\n",
      " [ 57 217]]\n",
      "recall:0.7922783451560429\n",
      "precision:0.7392706151816814\n",
      "accuracy:0.6980429608898605\n",
      "f1:0.7647823874238968\n",
      "\n",
      "Model: GaussianNB()\n",
      "confusion_mat: \n",
      " [[137  31]\n",
      " [134 140]]\n",
      "recall:0.5102086163237243\n",
      "precision:0.8193923070989638\n",
      "accuracy:0.6265112747651588\n",
      "f1:0.6284732638934178\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion_mat</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[90, 78], [47, 227]]</td>\n",
       "      <td>0.827445</td>\n",
       "      <td>0.744170</td>\n",
       "      <td>0.716858</td>\n",
       "      <td>0.783533</td>\n",
       "      <td>SVC()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[88, 80], [47, 227]]</td>\n",
       "      <td>0.827146</td>\n",
       "      <td>0.739257</td>\n",
       "      <td>0.712343</td>\n",
       "      <td>0.780668</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[91, 76], [57, 217]]</td>\n",
       "      <td>0.792278</td>\n",
       "      <td>0.739271</td>\n",
       "      <td>0.698043</td>\n",
       "      <td>0.764782</td>\n",
       "      <td>(ExtraTreeClassifier(random_state=255091077), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[88, 79], [58, 216]]</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.731760</td>\n",
       "      <td>0.689751</td>\n",
       "      <td>0.759086</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[90, 78], [59, 215]]</td>\n",
       "      <td>0.784636</td>\n",
       "      <td>0.733879</td>\n",
       "      <td>0.690503</td>\n",
       "      <td>0.758344</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[90, 77], [64, 210]]</td>\n",
       "      <td>0.766853</td>\n",
       "      <td>0.731350</td>\n",
       "      <td>0.680721</td>\n",
       "      <td>0.748427</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[86, 81], [63, 211]]</td>\n",
       "      <td>0.769632</td>\n",
       "      <td>0.720752</td>\n",
       "      <td>0.673166</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[90, 78], [67, 207]]</td>\n",
       "      <td>0.754728</td>\n",
       "      <td>0.726456</td>\n",
       "      <td>0.671684</td>\n",
       "      <td>0.740181</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[84, 84], [90, 184]]</td>\n",
       "      <td>0.672622</td>\n",
       "      <td>0.687715</td>\n",
       "      <td>0.606919</td>\n",
       "      <td>0.679608</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[137, 31], [134, 140]]</td>\n",
       "      <td>0.510209</td>\n",
       "      <td>0.819392</td>\n",
       "      <td>0.626511</td>\n",
       "      <td>0.628473</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             confusion_mat    recall  precision  accuracy        f1  \\\n",
       "2    [[90, 78], [47, 227]]  0.827445   0.744170  0.716858  0.783533   \n",
       "0    [[88, 80], [47, 227]]  0.827146   0.739257  0.712343  0.780668   \n",
       "8    [[91, 76], [57, 217]]  0.792278   0.739271  0.698043  0.764782   \n",
       "6    [[88, 79], [58, 216]]  0.788764   0.731760  0.689751  0.759086   \n",
       "1    [[90, 78], [59, 215]]  0.784636   0.733879  0.690503  0.758344   \n",
       "4    [[90, 77], [64, 210]]  0.766853   0.731350  0.680721  0.748427   \n",
       "3    [[86, 81], [63, 211]]  0.769632   0.720752  0.673166  0.744344   \n",
       "7    [[90, 78], [67, 207]]  0.754728   0.726456  0.671684  0.740181   \n",
       "5    [[84, 84], [90, 184]]  0.672622   0.687715  0.606919  0.679608   \n",
       "9  [[137, 31], [134, 140]]  0.510209   0.819392  0.626511  0.628473   \n",
       "\n",
       "                                          classifier  \n",
       "2                                              SVC()  \n",
       "0                               LogisticRegression()  \n",
       "8  (ExtraTreeClassifier(random_state=255091077), ...  \n",
       "6  ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "1  (DecisionTreeClassifier(max_features='sqrt', r...  \n",
       "4                             KNeighborsClassifier()  \n",
       "3  XGBClassifier(base_score=None, booster=None, c...  \n",
       "7  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "5                           DecisionTreeClassifier()  \n",
       "9                                       GaussianNB()  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "target = 'TARGET_5Yrs'\n",
    "balancer_method = 'NONE'\n",
    "\n",
    "features_selected = ['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA',\n",
    "       '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK',\n",
    "       'TOV', 'TARGET_5Yrs']\n",
    "features_to_scale = ['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA',\n",
    "       '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK',\n",
    "       'TOV']\n",
    "models = [LogisticRegression(), RandomForestClassifier(), SVC(), XGBClassifier(), \\\n",
    "          KNeighborsClassifier(), DecisionTreeClassifier(), GradientBoostingClassifier(), \\\n",
    "          AdaBoostClassifier(), ExtraTreesClassifier(), GaussianNB()]\n",
    "\n",
    "setps_prepocessing = [('duplicate_remover', DuplicateRemover()), \\\n",
    "    ('null_value_replacer', NullValueReplacer(columns=['3P%'], values=[0])), \\\n",
    "    ('data_balancer', DataBalancer(method=balancer_method)), \\\n",
    "    ('feature_selector', FeatureSelector(feature_names=features_selected)), \\\n",
    "    ('feature_scaler', FeatureScaler(feature_names=features_to_scale))]\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=setps_prepocessing)\n",
    "data_processed = pipeline.fit_transform(data)\n",
    "scores = []\n",
    "for model in models:\n",
    "    print(f\"Model: {model}\")\n",
    "    scores.append(score_classifier(data_processed.drop(target, axis=1), model,data_processed[target]))\n",
    "    print()\n",
    "\n",
    "scores = pd.DataFrame(scores)\n",
    "scores = scores.sort_values(by='f1', ascending=False)\n",
    "scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion_mat</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[90, 78], [47, 227]]</td>\n",
       "      <td>0.827445</td>\n",
       "      <td>0.744170</td>\n",
       "      <td>0.716858</td>\n",
       "      <td>0.783533</td>\n",
       "      <td>SVC()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[88, 80], [47, 227]]</td>\n",
       "      <td>0.827146</td>\n",
       "      <td>0.739257</td>\n",
       "      <td>0.712343</td>\n",
       "      <td>0.780668</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[91, 76], [57, 217]]</td>\n",
       "      <td>0.792278</td>\n",
       "      <td>0.739271</td>\n",
       "      <td>0.698043</td>\n",
       "      <td>0.764782</td>\n",
       "      <td>(ExtraTreeClassifier(random_state=255091077), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[88, 79], [58, 216]]</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.731760</td>\n",
       "      <td>0.689751</td>\n",
       "      <td>0.759086</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[90, 78], [59, 215]]</td>\n",
       "      <td>0.784636</td>\n",
       "      <td>0.733879</td>\n",
       "      <td>0.690503</td>\n",
       "      <td>0.758344</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[86, 81], [63, 211]]</td>\n",
       "      <td>0.769632</td>\n",
       "      <td>0.720752</td>\n",
       "      <td>0.673166</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[90, 77], [64, 210]]</td>\n",
       "      <td>0.766853</td>\n",
       "      <td>0.731350</td>\n",
       "      <td>0.680721</td>\n",
       "      <td>0.748427</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[90, 78], [67, 207]]</td>\n",
       "      <td>0.754728</td>\n",
       "      <td>0.726456</td>\n",
       "      <td>0.671684</td>\n",
       "      <td>0.740181</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[84, 84], [90, 184]]</td>\n",
       "      <td>0.672622</td>\n",
       "      <td>0.687715</td>\n",
       "      <td>0.606919</td>\n",
       "      <td>0.679608</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[137, 31], [134, 140]]</td>\n",
       "      <td>0.510209</td>\n",
       "      <td>0.819392</td>\n",
       "      <td>0.626511</td>\n",
       "      <td>0.628473</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             confusion_mat    recall  precision  accuracy        f1  \\\n",
       "2    [[90, 78], [47, 227]]  0.827445   0.744170  0.716858  0.783533   \n",
       "0    [[88, 80], [47, 227]]  0.827146   0.739257  0.712343  0.780668   \n",
       "8    [[91, 76], [57, 217]]  0.792278   0.739271  0.698043  0.764782   \n",
       "6    [[88, 79], [58, 216]]  0.788764   0.731760  0.689751  0.759086   \n",
       "1    [[90, 78], [59, 215]]  0.784636   0.733879  0.690503  0.758344   \n",
       "3    [[86, 81], [63, 211]]  0.769632   0.720752  0.673166  0.744344   \n",
       "4    [[90, 77], [64, 210]]  0.766853   0.731350  0.680721  0.748427   \n",
       "7    [[90, 78], [67, 207]]  0.754728   0.726456  0.671684  0.740181   \n",
       "5    [[84, 84], [90, 184]]  0.672622   0.687715  0.606919  0.679608   \n",
       "9  [[137, 31], [134, 140]]  0.510209   0.819392  0.626511  0.628473   \n",
       "\n",
       "                                          classifier  \n",
       "2                                              SVC()  \n",
       "0                               LogisticRegression()  \n",
       "8  (ExtraTreeClassifier(random_state=255091077), ...  \n",
       "6  ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "1  (DecisionTreeClassifier(max_features='sqrt', r...  \n",
       "3  XGBClassifier(base_score=None, booster=None, c...  \n",
       "4                             KNeighborsClassifier()  \n",
       "7  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "5                           DecisionTreeClassifier()  \n",
       "9                                       GaussianNB()  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = scores.sort_values(by='recall', ascending=False)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion_mat</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[137, 31], [134, 140]]</td>\n",
       "      <td>0.510209</td>\n",
       "      <td>0.819392</td>\n",
       "      <td>0.626511</td>\n",
       "      <td>0.628473</td>\n",
       "      <td>GaussianNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[90, 78], [47, 227]]</td>\n",
       "      <td>0.827445</td>\n",
       "      <td>0.744170</td>\n",
       "      <td>0.716858</td>\n",
       "      <td>0.783533</td>\n",
       "      <td>SVC()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[91, 76], [57, 217]]</td>\n",
       "      <td>0.792278</td>\n",
       "      <td>0.739271</td>\n",
       "      <td>0.698043</td>\n",
       "      <td>0.764782</td>\n",
       "      <td>(ExtraTreeClassifier(random_state=255091077), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[88, 80], [47, 227]]</td>\n",
       "      <td>0.827146</td>\n",
       "      <td>0.739257</td>\n",
       "      <td>0.712343</td>\n",
       "      <td>0.780668</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[90, 78], [59, 215]]</td>\n",
       "      <td>0.784636</td>\n",
       "      <td>0.733879</td>\n",
       "      <td>0.690503</td>\n",
       "      <td>0.758344</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[88, 79], [58, 216]]</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.731760</td>\n",
       "      <td>0.689751</td>\n",
       "      <td>0.759086</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[90, 77], [64, 210]]</td>\n",
       "      <td>0.766853</td>\n",
       "      <td>0.731350</td>\n",
       "      <td>0.680721</td>\n",
       "      <td>0.748427</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[90, 78], [67, 207]]</td>\n",
       "      <td>0.754728</td>\n",
       "      <td>0.726456</td>\n",
       "      <td>0.671684</td>\n",
       "      <td>0.740181</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[86, 81], [63, 211]]</td>\n",
       "      <td>0.769632</td>\n",
       "      <td>0.720752</td>\n",
       "      <td>0.673166</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[84, 84], [90, 184]]</td>\n",
       "      <td>0.672622</td>\n",
       "      <td>0.687715</td>\n",
       "      <td>0.606919</td>\n",
       "      <td>0.679608</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             confusion_mat    recall  precision  accuracy        f1  \\\n",
       "9  [[137, 31], [134, 140]]  0.510209   0.819392  0.626511  0.628473   \n",
       "2    [[90, 78], [47, 227]]  0.827445   0.744170  0.716858  0.783533   \n",
       "8    [[91, 76], [57, 217]]  0.792278   0.739271  0.698043  0.764782   \n",
       "0    [[88, 80], [47, 227]]  0.827146   0.739257  0.712343  0.780668   \n",
       "1    [[90, 78], [59, 215]]  0.784636   0.733879  0.690503  0.758344   \n",
       "6    [[88, 79], [58, 216]]  0.788764   0.731760  0.689751  0.759086   \n",
       "4    [[90, 77], [64, 210]]  0.766853   0.731350  0.680721  0.748427   \n",
       "7    [[90, 78], [67, 207]]  0.754728   0.726456  0.671684  0.740181   \n",
       "3    [[86, 81], [63, 211]]  0.769632   0.720752  0.673166  0.744344   \n",
       "5    [[84, 84], [90, 184]]  0.672622   0.687715  0.606919  0.679608   \n",
       "\n",
       "                                          classifier  \n",
       "9                                       GaussianNB()  \n",
       "2                                              SVC()  \n",
       "8  (ExtraTreeClassifier(random_state=255091077), ...  \n",
       "0                               LogisticRegression()  \n",
       "1  (DecisionTreeClassifier(max_features='sqrt', r...  \n",
       "6  ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "4                             KNeighborsClassifier()  \n",
       "7  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "3  XGBClassifier(base_score=None, booster=None, c...  \n",
       "5                           DecisionTreeClassifier()  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = scores.sort_values(by='precision', ascending=False)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier()\n",
      "Data balancer method: OVERSAMPLING\n",
      "confusion_mat: \n",
      " [[145  19]\n",
      " [ 36 128]]\n",
      "recall:0.7771752759074124\n",
      "precision:0.8710733557584867\n",
      "accuracy:0.8307211936999173\n",
      "f1:0.8210330456510091\n",
      "\n",
      "Data balancer method: UNDERSAMPLING\n",
      "confusion_mat: \n",
      " [[72 28]\n",
      " [23 77]]\n",
      "recall:0.7721337319655076\n",
      "precision:0.7337849013154035\n",
      "accuracy:0.7460568444904192\n",
      "f1:0.751047238787932\n",
      "\n",
      "Data balancer method: SMOTE\n",
      "confusion_mat: \n",
      " [[130  34]\n",
      " [ 48 116]]\n",
      "recall:0.7053978450703637\n",
      "precision:0.7744067706805209\n",
      "accuracy:0.7487795892051212\n",
      "f1:0.7366811295329709\n",
      "\n",
      "Data balancer method: NONE\n",
      "confusion_mat: \n",
      " [[ 52  48]\n",
      " [ 36 128]]\n",
      "recall:0.7803246277839301\n",
      "precision:0.7266773340332304\n",
      "accuracy:0.6814668747340048\n",
      "f1:0.7516997302458124\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: SVC()\n",
      "Data balancer method: OVERSAMPLING\n",
      "confusion_mat: \n",
      " [[123  41]\n",
      " [ 60 104]]\n",
      "recall:0.6353949838155477\n",
      "precision:0.7186512476407346\n",
      "accuracy:0.6917509440913696\n",
      "f1:0.6727748651485563\n",
      "\n",
      "Data balancer method: UNDERSAMPLING\n",
      "confusion_mat: \n",
      " [[70 30]\n",
      " [37 63]]\n",
      "recall:0.6309595406818371\n",
      "precision:0.680220913107511\n",
      "accuracy:0.6636815920398009\n",
      "f1:0.6513078678472018\n",
      "\n",
      "Data balancer method: SMOTE\n",
      "confusion_mat: \n",
      " [[123  41]\n",
      " [ 59 105]]\n",
      "recall:0.6385057524639443\n",
      "precision:0.7181763681573984\n",
      "accuracy:0.6923754259924473\n",
      "f1:0.6745302802741514\n",
      "\n",
      "Data balancer method: NONE\n",
      "confusion_mat: \n",
      " [[ 52  48]\n",
      " [ 27 137]]\n",
      "recall:0.8310106504800803\n",
      "precision:0.7371806744144294\n",
      "accuracy:0.7115619236771173\n",
      "f1:0.7806119375428051\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: LogisticRegression()\n",
      "Data balancer method: OVERSAMPLING\n",
      "confusion_mat: \n",
      " [[115  49]\n",
      " [ 50 114]]\n",
      "recall:0.692254220235915\n",
      "precision:0.6976897238750646\n",
      "accuracy:0.6953909919867367\n",
      "f1:0.6941130984130301\n",
      "\n",
      "Data balancer method: UNDERSAMPLING\n",
      "confusion_mat: \n",
      " [[70 30]\n",
      " [32 68]]\n",
      "recall:0.6779293829841226\n",
      "precision:0.6960781337525523\n",
      "accuracy:0.6865179055218954\n",
      "f1:0.682795352314097\n",
      "\n",
      "Data balancer method: SMOTE\n",
      "confusion_mat: \n",
      " [[115  49]\n",
      " [ 54 110]]\n",
      "recall:0.672736635795977\n",
      "precision:0.69557475423043\n",
      "accuracy:0.6869043013723866\n",
      "f1:0.6819303852866755\n",
      "\n",
      "Data balancer method: NONE\n",
      "confusion_mat: \n",
      " [[ 53  47]\n",
      " [ 28 136]]\n",
      "recall:0.824904069932827\n",
      "precision:0.7409173303743017\n",
      "accuracy:0.7123421761952049\n",
      "f1:0.7800004847145658\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "Data balancer method: OVERSAMPLING\n",
      "confusion_mat: \n",
      " [[138  26]\n",
      " [ 38 126]]\n",
      "recall:0.7697616525880641\n",
      "precision:0.8282517167517167\n",
      "accuracy:0.8046366399557888\n",
      "f1:0.7977132891504148\n",
      "\n",
      "Data balancer method: UNDERSAMPLING\n",
      "confusion_mat: \n",
      " [[70 30]\n",
      " [27 73]]\n",
      "recall:0.7252150945528782\n",
      "precision:0.7074065934065933\n",
      "accuracy:0.7133293926407565\n",
      "f1:0.7156164584438425\n",
      "\n",
      "Data balancer method: SMOTE\n",
      "confusion_mat: \n",
      " [[125  39]\n",
      " [ 49 115]]\n",
      "recall:0.7008594264740312\n",
      "precision:0.7491348666951221\n",
      "accuracy:0.7318098922354241\n",
      "f1:0.7231316396782634\n",
      "\n",
      "Data balancer method: NONE\n",
      "confusion_mat: \n",
      " [[ 52  48]\n",
      " [ 39 125]]\n",
      "recall:0.7596907460992232\n",
      "precision:0.7213736001596487\n",
      "accuracy:0.6686593843098312\n",
      "f1:0.7393511631846155\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion_mat</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>classifier</th>\n",
       "      <th>balancer_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[145, 19], [36, 128]]</td>\n",
       "      <td>0.777175</td>\n",
       "      <td>0.871073</td>\n",
       "      <td>0.830721</td>\n",
       "      <td>0.821033</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>OVERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[138, 26], [38, 126]]</td>\n",
       "      <td>0.769762</td>\n",
       "      <td>0.828252</td>\n",
       "      <td>0.804637</td>\n",
       "      <td>0.797713</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>OVERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[52, 48], [27, 137]]</td>\n",
       "      <td>0.831011</td>\n",
       "      <td>0.737181</td>\n",
       "      <td>0.711562</td>\n",
       "      <td>0.780612</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[53, 47], [28, 136]]</td>\n",
       "      <td>0.824904</td>\n",
       "      <td>0.740917</td>\n",
       "      <td>0.712342</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[52, 48], [36, 128]]</td>\n",
       "      <td>0.780325</td>\n",
       "      <td>0.726677</td>\n",
       "      <td>0.681467</td>\n",
       "      <td>0.751700</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[72, 28], [23, 77]]</td>\n",
       "      <td>0.772134</td>\n",
       "      <td>0.733785</td>\n",
       "      <td>0.746057</td>\n",
       "      <td>0.751047</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>UNDERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[[52, 48], [39, 125]]</td>\n",
       "      <td>0.759691</td>\n",
       "      <td>0.721374</td>\n",
       "      <td>0.668659</td>\n",
       "      <td>0.739351</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[130, 34], [48, 116]]</td>\n",
       "      <td>0.705398</td>\n",
       "      <td>0.774407</td>\n",
       "      <td>0.748780</td>\n",
       "      <td>0.736681</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[[125, 39], [49, 115]]</td>\n",
       "      <td>0.700859</td>\n",
       "      <td>0.749135</td>\n",
       "      <td>0.731810</td>\n",
       "      <td>0.723132</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[70, 30], [27, 73]]</td>\n",
       "      <td>0.725215</td>\n",
       "      <td>0.707407</td>\n",
       "      <td>0.713329</td>\n",
       "      <td>0.715616</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>UNDERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[115, 49], [50, 114]]</td>\n",
       "      <td>0.692254</td>\n",
       "      <td>0.697690</td>\n",
       "      <td>0.695391</td>\n",
       "      <td>0.694113</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>OVERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[70, 30], [32, 68]]</td>\n",
       "      <td>0.677929</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.686518</td>\n",
       "      <td>0.682795</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>UNDERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[115, 49], [54, 110]]</td>\n",
       "      <td>0.672737</td>\n",
       "      <td>0.695575</td>\n",
       "      <td>0.686904</td>\n",
       "      <td>0.681930</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[123, 41], [59, 105]]</td>\n",
       "      <td>0.638506</td>\n",
       "      <td>0.718176</td>\n",
       "      <td>0.692375</td>\n",
       "      <td>0.674530</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[123, 41], [60, 104]]</td>\n",
       "      <td>0.635395</td>\n",
       "      <td>0.718651</td>\n",
       "      <td>0.691751</td>\n",
       "      <td>0.672775</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>OVERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[70, 30], [37, 63]]</td>\n",
       "      <td>0.630960</td>\n",
       "      <td>0.680221</td>\n",
       "      <td>0.663682</td>\n",
       "      <td>0.651308</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>UNDERSAMPLING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             confusion_mat    recall  precision  accuracy        f1  \\\n",
       "0   [[145, 19], [36, 128]]  0.777175   0.871073  0.830721  0.821033   \n",
       "12  [[138, 26], [38, 126]]  0.769762   0.828252  0.804637  0.797713   \n",
       "7    [[52, 48], [27, 137]]  0.831011   0.737181  0.711562  0.780612   \n",
       "11   [[53, 47], [28, 136]]  0.824904   0.740917  0.712342  0.780000   \n",
       "3    [[52, 48], [36, 128]]  0.780325   0.726677  0.681467  0.751700   \n",
       "1     [[72, 28], [23, 77]]  0.772134   0.733785  0.746057  0.751047   \n",
       "15   [[52, 48], [39, 125]]  0.759691   0.721374  0.668659  0.739351   \n",
       "2   [[130, 34], [48, 116]]  0.705398   0.774407  0.748780  0.736681   \n",
       "14  [[125, 39], [49, 115]]  0.700859   0.749135  0.731810  0.723132   \n",
       "13    [[70, 30], [27, 73]]  0.725215   0.707407  0.713329  0.715616   \n",
       "8   [[115, 49], [50, 114]]  0.692254   0.697690  0.695391  0.694113   \n",
       "9     [[70, 30], [32, 68]]  0.677929   0.696078  0.686518  0.682795   \n",
       "10  [[115, 49], [54, 110]]  0.672737   0.695575  0.686904  0.681930   \n",
       "6   [[123, 41], [59, 105]]  0.638506   0.718176  0.692375  0.674530   \n",
       "4   [[123, 41], [60, 104]]  0.635395   0.718651  0.691751  0.672775   \n",
       "5     [[70, 30], [37, 63]]  0.630960   0.680221  0.663682  0.651308   \n",
       "\n",
       "                                           classifier balancer_method  \n",
       "0   (DecisionTreeClassifier(max_features='sqrt', r...    OVERSAMPLING  \n",
       "12  XGBClassifier(base_score=None, booster=None, c...    OVERSAMPLING  \n",
       "7                                               SVC()            NONE  \n",
       "11                               LogisticRegression()            NONE  \n",
       "3   (DecisionTreeClassifier(max_features='sqrt', r...            NONE  \n",
       "1   (DecisionTreeClassifier(max_features='sqrt', r...   UNDERSAMPLING  \n",
       "15  XGBClassifier(base_score=None, booster=None, c...            NONE  \n",
       "2   (DecisionTreeClassifier(max_features='sqrt', r...           SMOTE  \n",
       "14  XGBClassifier(base_score=None, booster=None, c...           SMOTE  \n",
       "13  XGBClassifier(base_score=None, booster=None, c...   UNDERSAMPLING  \n",
       "8                                LogisticRegression()    OVERSAMPLING  \n",
       "9                                LogisticRegression()   UNDERSAMPLING  \n",
       "10                               LogisticRegression()           SMOTE  \n",
       "6                                               SVC()           SMOTE  \n",
       "4                                               SVC()    OVERSAMPLING  \n",
       "5                                               SVC()   UNDERSAMPLING  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'TARGET_5Yrs'\n",
    "balancer_methods = ['OVERSAMPLING', 'UNDERSAMPLING', 'SMOTE', 'NONE']\n",
    "\n",
    "features_selected = ['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA',\n",
    "       '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK',\n",
    "       'TOV', 'TARGET_5Yrs']\n",
    "features_to_scale = ['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA',\n",
    "       '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK',\n",
    "       'TOV']\n",
    "models = [RandomForestClassifier(), SVC(), LogisticRegression(), XGBClassifier()]\n",
    "          \n",
    "\n",
    "setps_prepocessing = [\n",
    "    ('feature_selector', FeatureSelector(feature_names=features_selected)), \\\n",
    "    ('duplicate_remover', DuplicateRemover()), \\\n",
    "    ('null_value_replacer', NullValueReplacer(columns=['3P%'], values=[0])), \\\n",
    "    ('data_balancer', DataBalancer(method=balancer_method)), \\\n",
    "    ('feature_scaler', FeatureScaler(feature_names=features_to_scale))]\n",
    "\n",
    "scores_equilibration = []\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Model: {model}\")\n",
    "    for balancer_method in balancer_methods:\n",
    "        setps_prepocessing = [\n",
    "    ('feature_selector', FeatureSelector(feature_names=features_selected)), \\\n",
    "    ('duplicate_remover', DuplicateRemover()), \\\n",
    "    ('null_value_replacer', NullValueReplacer(columns=['3P%'], values=[0])), \\\n",
    "    ('data_balancer', DataBalancer(method=balancer_method)), \\\n",
    "    ('feature_scaler', FeatureScaler(feature_names=features_to_scale))]\n",
    "        pipeline = Pipeline(steps=setps_prepocessing)\n",
    "        data_processed = pipeline.fit_transform(data)\n",
    "        print(f\"Data balancer method: {balancer_method}\")\n",
    "        score_eq = score_classifier(data_processed.drop(target, axis=1), model,data_processed[target], folds=5)\n",
    "        score_eq['balancer_method'] = balancer_method\n",
    "        scores_equilibration.append(score_eq)\n",
    "        print()\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "scores_equilibration = pd.DataFrame(scores_equilibration)\n",
    "scores_equilibration = scores_equilibration.sort_values(by='f1', ascending=False)\n",
    "scores_equilibration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion_mat</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>classifier</th>\n",
       "      <th>balancer_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[52, 48], [27, 137]]</td>\n",
       "      <td>0.831011</td>\n",
       "      <td>0.737181</td>\n",
       "      <td>0.711562</td>\n",
       "      <td>0.780612</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[53, 47], [28, 136]]</td>\n",
       "      <td>0.824904</td>\n",
       "      <td>0.740917</td>\n",
       "      <td>0.712342</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[53, 47], [37, 127]]</td>\n",
       "      <td>0.770069</td>\n",
       "      <td>0.726960</td>\n",
       "      <td>0.678442</td>\n",
       "      <td>0.747332</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[146, 18], [39, 125]]</td>\n",
       "      <td>0.761988</td>\n",
       "      <td>0.874090</td>\n",
       "      <td>0.825862</td>\n",
       "      <td>0.813783</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>OVERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[75, 25], [27, 73]]</td>\n",
       "      <td>0.733120</td>\n",
       "      <td>0.746990</td>\n",
       "      <td>0.739097</td>\n",
       "      <td>0.736290</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>UNDERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[129, 35], [48, 116]]</td>\n",
       "      <td>0.704332</td>\n",
       "      <td>0.767616</td>\n",
       "      <td>0.743944</td>\n",
       "      <td>0.733297</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[71, 29], [32, 68]]</td>\n",
       "      <td>0.681751</td>\n",
       "      <td>0.704767</td>\n",
       "      <td>0.697404</td>\n",
       "      <td>0.691939</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>UNDERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[115, 49], [54, 110]]</td>\n",
       "      <td>0.672737</td>\n",
       "      <td>0.695575</td>\n",
       "      <td>0.686904</td>\n",
       "      <td>0.681930</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[118, 46], [54, 110]]</td>\n",
       "      <td>0.669308</td>\n",
       "      <td>0.701974</td>\n",
       "      <td>0.692357</td>\n",
       "      <td>0.684575</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>OVERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[73, 27], [33, 67]]</td>\n",
       "      <td>0.664102</td>\n",
       "      <td>0.714001</td>\n",
       "      <td>0.698365</td>\n",
       "      <td>0.686290</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>UNDERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[123, 41], [59, 105]]</td>\n",
       "      <td>0.638506</td>\n",
       "      <td>0.718176</td>\n",
       "      <td>0.692375</td>\n",
       "      <td>0.674530</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[122, 42], [61, 103]]</td>\n",
       "      <td>0.629212</td>\n",
       "      <td>0.711133</td>\n",
       "      <td>0.685064</td>\n",
       "      <td>0.665899</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>OVERSAMPLING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             confusion_mat    recall  precision  accuracy        f1  \\\n",
       "7    [[52, 48], [27, 137]]  0.831011   0.737181  0.711562  0.780612   \n",
       "11   [[53, 47], [28, 136]]  0.824904   0.740917  0.712342  0.780000   \n",
       "3    [[53, 47], [37, 127]]  0.770069   0.726960  0.678442  0.747332   \n",
       "0   [[146, 18], [39, 125]]  0.761988   0.874090  0.825862  0.813783   \n",
       "1     [[75, 25], [27, 73]]  0.733120   0.746990  0.739097  0.736290   \n",
       "2   [[129, 35], [48, 116]]  0.704332   0.767616  0.743944  0.733297   \n",
       "9     [[71, 29], [32, 68]]  0.681751   0.704767  0.697404  0.691939   \n",
       "10  [[115, 49], [54, 110]]  0.672737   0.695575  0.686904  0.681930   \n",
       "8   [[118, 46], [54, 110]]  0.669308   0.701974  0.692357  0.684575   \n",
       "5     [[73, 27], [33, 67]]  0.664102   0.714001  0.698365  0.686290   \n",
       "6   [[123, 41], [59, 105]]  0.638506   0.718176  0.692375  0.674530   \n",
       "4   [[122, 42], [61, 103]]  0.629212   0.711133  0.685064  0.665899   \n",
       "\n",
       "                                           classifier balancer_method  \n",
       "7                                               SVC()            NONE  \n",
       "11                               LogisticRegression()            NONE  \n",
       "3   (DecisionTreeClassifier(max_features='sqrt', r...            NONE  \n",
       "0   (DecisionTreeClassifier(max_features='sqrt', r...    OVERSAMPLING  \n",
       "1   (DecisionTreeClassifier(max_features='sqrt', r...   UNDERSAMPLING  \n",
       "2   (DecisionTreeClassifier(max_features='sqrt', r...           SMOTE  \n",
       "9                                LogisticRegression()   UNDERSAMPLING  \n",
       "10                               LogisticRegression()           SMOTE  \n",
       "8                                LogisticRegression()    OVERSAMPLING  \n",
       "5                                               SVC()   UNDERSAMPLING  \n",
       "6                                               SVC()           SMOTE  \n",
       "4                                               SVC()    OVERSAMPLING  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_equilibration = scores_equilibration.sort_values(by='recall', ascending=False)\n",
    "scores_equilibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion_mat</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>classifier</th>\n",
       "      <th>balancer_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[146, 18], [39, 125]]</td>\n",
       "      <td>0.761988</td>\n",
       "      <td>0.874090</td>\n",
       "      <td>0.825862</td>\n",
       "      <td>0.813783</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>OVERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[129, 35], [48, 116]]</td>\n",
       "      <td>0.704332</td>\n",
       "      <td>0.767616</td>\n",
       "      <td>0.743944</td>\n",
       "      <td>0.733297</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[75, 25], [27, 73]]</td>\n",
       "      <td>0.733120</td>\n",
       "      <td>0.746990</td>\n",
       "      <td>0.739097</td>\n",
       "      <td>0.736290</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>UNDERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[53, 47], [28, 136]]</td>\n",
       "      <td>0.824904</td>\n",
       "      <td>0.740917</td>\n",
       "      <td>0.712342</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[52, 48], [27, 137]]</td>\n",
       "      <td>0.831011</td>\n",
       "      <td>0.737181</td>\n",
       "      <td>0.711562</td>\n",
       "      <td>0.780612</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[53, 47], [37, 127]]</td>\n",
       "      <td>0.770069</td>\n",
       "      <td>0.726960</td>\n",
       "      <td>0.678442</td>\n",
       "      <td>0.747332</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[123, 41], [59, 105]]</td>\n",
       "      <td>0.638506</td>\n",
       "      <td>0.718176</td>\n",
       "      <td>0.692375</td>\n",
       "      <td>0.674530</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[73, 27], [33, 67]]</td>\n",
       "      <td>0.664102</td>\n",
       "      <td>0.714001</td>\n",
       "      <td>0.698365</td>\n",
       "      <td>0.686290</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>UNDERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[122, 42], [61, 103]]</td>\n",
       "      <td>0.629212</td>\n",
       "      <td>0.711133</td>\n",
       "      <td>0.685064</td>\n",
       "      <td>0.665899</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>OVERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[71, 29], [32, 68]]</td>\n",
       "      <td>0.681751</td>\n",
       "      <td>0.704767</td>\n",
       "      <td>0.697404</td>\n",
       "      <td>0.691939</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>UNDERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[118, 46], [54, 110]]</td>\n",
       "      <td>0.669308</td>\n",
       "      <td>0.701974</td>\n",
       "      <td>0.692357</td>\n",
       "      <td>0.684575</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>OVERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[115, 49], [54, 110]]</td>\n",
       "      <td>0.672737</td>\n",
       "      <td>0.695575</td>\n",
       "      <td>0.686904</td>\n",
       "      <td>0.681930</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             confusion_mat    recall  precision  accuracy        f1  \\\n",
       "0   [[146, 18], [39, 125]]  0.761988   0.874090  0.825862  0.813783   \n",
       "2   [[129, 35], [48, 116]]  0.704332   0.767616  0.743944  0.733297   \n",
       "1     [[75, 25], [27, 73]]  0.733120   0.746990  0.739097  0.736290   \n",
       "11   [[53, 47], [28, 136]]  0.824904   0.740917  0.712342  0.780000   \n",
       "7    [[52, 48], [27, 137]]  0.831011   0.737181  0.711562  0.780612   \n",
       "3    [[53, 47], [37, 127]]  0.770069   0.726960  0.678442  0.747332   \n",
       "6   [[123, 41], [59, 105]]  0.638506   0.718176  0.692375  0.674530   \n",
       "5     [[73, 27], [33, 67]]  0.664102   0.714001  0.698365  0.686290   \n",
       "4   [[122, 42], [61, 103]]  0.629212   0.711133  0.685064  0.665899   \n",
       "9     [[71, 29], [32, 68]]  0.681751   0.704767  0.697404  0.691939   \n",
       "8   [[118, 46], [54, 110]]  0.669308   0.701974  0.692357  0.684575   \n",
       "10  [[115, 49], [54, 110]]  0.672737   0.695575  0.686904  0.681930   \n",
       "\n",
       "                                           classifier balancer_method  \n",
       "0   (DecisionTreeClassifier(max_features='sqrt', r...    OVERSAMPLING  \n",
       "2   (DecisionTreeClassifier(max_features='sqrt', r...           SMOTE  \n",
       "1   (DecisionTreeClassifier(max_features='sqrt', r...   UNDERSAMPLING  \n",
       "11                               LogisticRegression()            NONE  \n",
       "7                                               SVC()            NONE  \n",
       "3   (DecisionTreeClassifier(max_features='sqrt', r...            NONE  \n",
       "6                                               SVC()           SMOTE  \n",
       "5                                               SVC()   UNDERSAMPLING  \n",
       "4                                               SVC()    OVERSAMPLING  \n",
       "9                                LogisticRegression()   UNDERSAMPLING  \n",
       "8                                LogisticRegression()    OVERSAMPLING  \n",
       "10                               LogisticRegression()           SMOTE  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_equilibration = scores_equilibration.sort_values(by='precision', ascending=False)\n",
    "scores_equilibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion_mat</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>classifier</th>\n",
       "      <th>balancer_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[146, 18], [39, 125]]</td>\n",
       "      <td>0.761988</td>\n",
       "      <td>0.874090</td>\n",
       "      <td>0.825862</td>\n",
       "      <td>0.813783</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>OVERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[129, 35], [48, 116]]</td>\n",
       "      <td>0.704332</td>\n",
       "      <td>0.767616</td>\n",
       "      <td>0.743944</td>\n",
       "      <td>0.733297</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[75, 25], [27, 73]]</td>\n",
       "      <td>0.733120</td>\n",
       "      <td>0.746990</td>\n",
       "      <td>0.739097</td>\n",
       "      <td>0.736290</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>UNDERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[53, 47], [28, 136]]</td>\n",
       "      <td>0.824904</td>\n",
       "      <td>0.740917</td>\n",
       "      <td>0.712342</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[52, 48], [27, 137]]</td>\n",
       "      <td>0.831011</td>\n",
       "      <td>0.737181</td>\n",
       "      <td>0.711562</td>\n",
       "      <td>0.780612</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[73, 27], [33, 67]]</td>\n",
       "      <td>0.664102</td>\n",
       "      <td>0.714001</td>\n",
       "      <td>0.698365</td>\n",
       "      <td>0.686290</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>UNDERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[71, 29], [32, 68]]</td>\n",
       "      <td>0.681751</td>\n",
       "      <td>0.704767</td>\n",
       "      <td>0.697404</td>\n",
       "      <td>0.691939</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>UNDERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[123, 41], [59, 105]]</td>\n",
       "      <td>0.638506</td>\n",
       "      <td>0.718176</td>\n",
       "      <td>0.692375</td>\n",
       "      <td>0.674530</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[118, 46], [54, 110]]</td>\n",
       "      <td>0.669308</td>\n",
       "      <td>0.701974</td>\n",
       "      <td>0.692357</td>\n",
       "      <td>0.684575</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>OVERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[115, 49], [54, 110]]</td>\n",
       "      <td>0.672737</td>\n",
       "      <td>0.695575</td>\n",
       "      <td>0.686904</td>\n",
       "      <td>0.681930</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[122, 42], [61, 103]]</td>\n",
       "      <td>0.629212</td>\n",
       "      <td>0.711133</td>\n",
       "      <td>0.685064</td>\n",
       "      <td>0.665899</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>OVERSAMPLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[53, 47], [37, 127]]</td>\n",
       "      <td>0.770069</td>\n",
       "      <td>0.726960</td>\n",
       "      <td>0.678442</td>\n",
       "      <td>0.747332</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             confusion_mat    recall  precision  accuracy        f1  \\\n",
       "0   [[146, 18], [39, 125]]  0.761988   0.874090  0.825862  0.813783   \n",
       "2   [[129, 35], [48, 116]]  0.704332   0.767616  0.743944  0.733297   \n",
       "1     [[75, 25], [27, 73]]  0.733120   0.746990  0.739097  0.736290   \n",
       "11   [[53, 47], [28, 136]]  0.824904   0.740917  0.712342  0.780000   \n",
       "7    [[52, 48], [27, 137]]  0.831011   0.737181  0.711562  0.780612   \n",
       "5     [[73, 27], [33, 67]]  0.664102   0.714001  0.698365  0.686290   \n",
       "9     [[71, 29], [32, 68]]  0.681751   0.704767  0.697404  0.691939   \n",
       "6   [[123, 41], [59, 105]]  0.638506   0.718176  0.692375  0.674530   \n",
       "8   [[118, 46], [54, 110]]  0.669308   0.701974  0.692357  0.684575   \n",
       "10  [[115, 49], [54, 110]]  0.672737   0.695575  0.686904  0.681930   \n",
       "4   [[122, 42], [61, 103]]  0.629212   0.711133  0.685064  0.665899   \n",
       "3    [[53, 47], [37, 127]]  0.770069   0.726960  0.678442  0.747332   \n",
       "\n",
       "                                           classifier balancer_method  \n",
       "0   (DecisionTreeClassifier(max_features='sqrt', r...    OVERSAMPLING  \n",
       "2   (DecisionTreeClassifier(max_features='sqrt', r...           SMOTE  \n",
       "1   (DecisionTreeClassifier(max_features='sqrt', r...   UNDERSAMPLING  \n",
       "11                               LogisticRegression()            NONE  \n",
       "7                                               SVC()            NONE  \n",
       "5                                               SVC()   UNDERSAMPLING  \n",
       "9                                LogisticRegression()   UNDERSAMPLING  \n",
       "6                                               SVC()           SMOTE  \n",
       "8                                LogisticRegression()    OVERSAMPLING  \n",
       "10                               LogisticRegression()           SMOTE  \n",
       "4                                               SVC()    OVERSAMPLING  \n",
       "3   (DecisionTreeClassifier(max_features='sqrt', r...            NONE  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_equilibration = scores_equilibration.sort_values(by='accuracy', ascending=False)\n",
    "scores_equilibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Définir les hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale'] }\n",
    "\n",
    "target = 'TARGET_5Yrs'\n",
    "balancer_method = 'NONE'\n",
    "\n",
    "features_selected = ['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA',\n",
    "       '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK',\n",
    "       'TOV', 'TARGET_5Yrs']\n",
    "features_to_scale = ['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA',\n",
    "       '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK',\n",
    "       'TOV']\n",
    "models = [LogisticRegression(), RandomForestClassifier(), SVC(), XGBClassifier(), \\\n",
    "          KNeighborsClassifier(), DecisionTreeClassifier(), GradientBoostingClassifier(), \\\n",
    "          AdaBoostClassifier(), ExtraTreesClassifier(), GaussianNB()]\n",
    "\n",
    "setps_prepocessing = [('duplicate_remover', DuplicateRemover()), \\\n",
    "    ('null_value_replacer', NullValueReplacer(columns=['3P%'], values=[0])), \\\n",
    "    ('data_balancer', DataBalancer(method=balancer_method)), \\\n",
    "    ('feature_selector', FeatureSelector(feature_names=features_selected)), \\\n",
    "    ('feature_scaler', FeatureScaler(feature_names=features_to_scale))]\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=setps_prepocessing)\n",
    "data_processed = pipeline.fit_transform(data)\n",
    "\n",
    "scoring_list = ['recall', 'f1']\n",
    "best_params = {}\n",
    "for score in scoring_list:\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring=score)\n",
    "    grid_search.fit(data_processed.drop(target, axis=1), data_processed[target])\n",
    "    best_params[score] = grid_search.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters :  {'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'},\n",
       " 'f1': {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring method: recall\n",
      "confusion_mat: \n",
      " [[ 84  84]\n",
      " [ 44 230]]\n",
      "recall:0.8374519964448023\n",
      "precision:0.732325401231503\n",
      "accuracy:0.7093262378749033\n",
      "f1:0.7811665404589574\n",
      "\n",
      "scoring method: f1\n",
      "confusion_mat: \n",
      " [[ 84  84]\n",
      " [ 44 230]]\n",
      "recall:0.8374519964448023\n",
      "precision:0.732325401231503\n",
      "accuracy:0.7093262378749033\n",
      "f1:0.7811665404589574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_processed = pipeline.fit_transform(data)\n",
    "\n",
    "scores = []\n",
    "for scoring in scoring_list:\n",
    "    params = best_params[scoring]\n",
    "    model = SVC(**params)\n",
    "    print(f\"scoring method: {scoring}\")\n",
    "    score = score_classifier(data_processed.drop(target, axis=1), model, data_processed[target])\n",
    "    scores.append(score)\n",
    "    print()\n",
    "\n",
    "scores = pd.DataFrame(scores)\n",
    "scores = scores.sort_values(by='f1', ascending=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('duplicate_remover', DuplicateRemover()),\n",
      "                ('null_value_replacer', NullValueReplacer()),\n",
      "                ('data_balancer', DataBalancer(method='NONE')),\n",
      "                ('feature_selector',\n",
      "                 FeatureSelector(feature_names=['GP', 'MIN', 'PTS', 'FGM',\n",
      "                                                'FGA', 'FG%', '3P Made', '3PA',\n",
      "                                                '3P%', 'FTM', 'FTA', 'FT%',\n",
      "                                                'OREB', 'DREB', 'REB', 'AST',\n",
      "                                                'STL', 'BLK', 'TOV',\n",
      "                                                'TARGET_5Yrs'])),\n",
      "                ('polynomial_features', PolynomialFeatures(include_bias=False)),\n",
      "                ('select_k_best', SelectKBest()),\n",
      "                ('feature_scaler',\n",
      "                 FeatureScaler(feature_names=['GP', 'MIN', 'PTS', 'FGM', 'FGA',\n",
      "                                              'FG%', '3P Made', '3PA', '3P%',\n",
      "                                              'FTM', 'FTA', 'FT%', 'OREB',\n",
      "                                              'DREB', 'REB', 'AST', 'STL',\n",
      "                                              'BLK', 'TOV'])),\n",
      "                ('model', SVC())])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "target = 'TARGET_5Yrs'\n",
    "balancer_method = 'NONE'\n",
    "\n",
    "features_selected = ['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA',\n",
    "       '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK',\n",
    "       'TOV', 'TARGET_5Yrs']\n",
    "features_to_scale = ['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA',\n",
    "       '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK',\n",
    "       'TOV']\n",
    "model = SVC()\n",
    "\n",
    "setps_prepocessing = [('duplicate_remover', DuplicateRemover()), \\\n",
    "    ('null_value_replacer', NullValueReplacer(columns=['3P%'], values=[0])), \\\n",
    "    ('data_balancer', DataBalancer(method=balancer_method)), \\\n",
    "    ('feature_selector', FeatureSelector(feature_names=features_selected)), \\\n",
    "    ('polynomial_features', PolynomialFeatures(2, include_bias=False)), \\\n",
    "    ('select_k_best', SelectKBest(f_classif, k=10)), \\\n",
    "    ('feature_scaler', FeatureScaler(feature_names=features_to_scale)), \\\n",
    "    ('model', model)]\n",
    "\n",
    "\n",
    "\n",
    "pipeline_processing = Pipeline(steps=setps_prepocessing)\n",
    "print(pipeline_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'polynomial_features__degree': [1, 2, 3, 4], \\\n",
    "                     'select_k_best__k': range(4,100), \\\n",
    "                        'model__C': [0.1, 1, 10, 100], \\\n",
    "                            'model__kernel': ['linear', 'rbf', 'poly'], \\\n",
    "                                'model__gamma': ['scale']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;polynomial_features&#x27;,\n",
       "                                              PolynomialFeatures(include_bias=False)),\n",
       "                                             (&#x27;select_k_best&#x27;, SelectKBest()),\n",
       "                                             (&#x27;classifier&#x27;, SVC())]),\n",
       "                   param_distributions={&#x27;classifier__C&#x27;: [0.1, 1, 10, 100],\n",
       "                                        &#x27;classifier__gamma&#x27;: [&#x27;scale&#x27;],\n",
       "                                        &#x27;classifier__kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;,\n",
       "                                                               &#x27;poly&#x27;],\n",
       "                                        &#x27;polynomial_features__degree&#x27;: [1, 2, 3,\n",
       "                                                                        4],\n",
       "                                        &#x27;select_k_best__k&#x27;: range(4, 20)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;polynomial_features&#x27;,\n",
       "                                              PolynomialFeatures(include_bias=False)),\n",
       "                                             (&#x27;select_k_best&#x27;, SelectKBest()),\n",
       "                                             (&#x27;classifier&#x27;, SVC())]),\n",
       "                   param_distributions={&#x27;classifier__C&#x27;: [0.1, 1, 10, 100],\n",
       "                                        &#x27;classifier__gamma&#x27;: [&#x27;scale&#x27;],\n",
       "                                        &#x27;classifier__kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;,\n",
       "                                                               &#x27;poly&#x27;],\n",
       "                                        &#x27;polynomial_features__degree&#x27;: [1, 2, 3,\n",
       "                                                                        4],\n",
       "                                        &#x27;select_k_best__k&#x27;: range(4, 20)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;polynomial_features&#x27;, PolynomialFeatures(include_bias=False)),\n",
       "                (&#x27;select_k_best&#x27;, SelectKBest()), (&#x27;classifier&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('polynomial_features',\n",
       "                                              PolynomialFeatures(include_bias=False)),\n",
       "                                             ('select_k_best', SelectKBest()),\n",
       "                                             ('classifier', SVC())]),\n",
       "                   param_distributions={'classifier__C': [0.1, 1, 10, 100],\n",
       "                                        'classifier__gamma': ['scale'],\n",
       "                                        'classifier__kernel': ['linear', 'rbf',\n",
       "                                                               'poly'],\n",
       "                                        'polynomial_features__degree': [1, 2, 3,\n",
       "                                                                        4],\n",
       "                                        'select_k_best__k': range(4, 20)})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "target = 'TARGET_5Yrs'\n",
    "balancer_method = 'NONE'\n",
    "\n",
    "features_selected = ['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA',\n",
    "       '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK',\n",
    "       'TOV', 'TARGET_5Yrs']\n",
    "features_to_scale = ['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA',\n",
    "       '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK',\n",
    "       'TOV']\n",
    "\n",
    "# Define your transformers\n",
    "duplicate_remover = DuplicateRemover()\n",
    "null_value_replacer = NullValueReplacer()\n",
    "data_balancer = DataBalancer()\n",
    "feature_selector = FeatureSelector(feature_names=features_selected)  # replace with your feature names\n",
    "feature_scaler = FeatureScaler(feature_names=features_to_scale)  # replace with your feature names\n",
    "\n",
    "# Define your classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline_processing\t = Pipeline(steps=[\n",
    "    ('duplicate_remover', duplicate_remover),\n",
    "    ('null_value_replacer', null_value_replacer),\n",
    "    ('data_balancer', data_balancer),\n",
    "    ('feature_selector', feature_selector),\n",
    "    ('feature_scaler', feature_scaler),\n",
    "])\n",
    "\n",
    "data_processed = pipeline_processing.fit_transform(data)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('polynomial_features', PolynomialFeatures(2, include_bias=False)),\n",
    "    ('select_k_best', SelectKBest(f_classif, k=10)),\n",
    "    ('classifier', clf)])\n",
    "\n",
    "# Define the parameter grid for the classifier\n",
    "param_grid = {'polynomial_features__degree': [1, 2, 3, 4], \\\n",
    "                     'select_k_best__k': range(4, 20), \\\n",
    "                        'classifier__C': [0.1, 1, 10, 100], \\\n",
    "                            'classifier__kernel': ['linear', 'rbf', 'poly'], \\\n",
    "                                'classifier__gamma': ['scale']}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid = RandomizedSearchCV(pipeline, param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid.fit(data_processed.drop(target, axis=1), data_processed[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'select_k_best__k': 16, 'polynomial_features__degree': 3, 'classifier__kernel': 'poly', 'classifier__gamma': 'scale', 'classifier__C': 100}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 160 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n160 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\julie\\AppData\\Local\\Temp\\ipykernel_11304\\1553731196.py\", line 46, in transform\n    X.loc[:, column] = X.loc[:, column].fillna(self.values[i])\nAttributeError: 'tuple' object has no attribute 'loc'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\notebooks\\model_exploration.ipynb Cell 29\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/Professionnels/Stage_fin_etude/MPDATA/NBA_prediction/notebooks/model_exploration.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomizedSearchCV\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/Professionnels/Stage_fin_etude/MPDATA/NBA_prediction/notebooks/model_exploration.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m grid \u001b[39m=\u001b[39m RandomizedSearchCV(pipeline_processing, param_distributions\u001b[39m=\u001b[39mhyperparameters, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/Professionnels/Stage_fin_etude/MPDATA/NBA_prediction/notebooks/model_exploration.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                           n_iter\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents/Professionnels/Stage_fin_etude/MPDATA/NBA_prediction/notebooks/model_exploration.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m grid\u001b[39m.\u001b[39;49mfit(data\u001b[39m.\u001b[39;49mdrop(target, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), data[target])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/Professionnels/Stage_fin_etude/MPDATA/NBA_prediction/notebooks/model_exploration.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(grid\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32md:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1807\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1808\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1809\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1810\u001b[0m         ParameterSampler(\n\u001b[0;32m   1811\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1812\u001b[0m         )\n\u001b[0;32m   1813\u001b[0m     )\n",
      "File \u001b[1;32md:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[0;32m    869\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 875\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[0;32m    877\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[1;32md:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 160 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n160 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"d:\\Documents\\Professionnels\\Stage_fin_etude\\MPDATA\\NBA_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\julie\\AppData\\Local\\Temp\\ipykernel_11304\\1553731196.py\", line 46, in transform\n    X.loc[:, column] = X.loc[:, column].fillna(self.values[i])\nAttributeError: 'tuple' object has no attribute 'loc'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid = RandomizedSearchCV(pipeline_processing, param_distributions=hyperparameters, scoring='recall', cv=4,\n",
    "                          n_iter=40)\n",
    "\n",
    "grid.fit(data.drop(target, axis=1), data[target])\n",
    "\n",
    "print(grid.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
