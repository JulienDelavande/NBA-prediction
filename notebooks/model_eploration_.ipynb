{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_column', None)\n",
    "\n",
    "data_path = './../data/nba_logreg.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "def preprocessing(data, method=None):\n",
    "    data = data.drop(['Name'], axis=1)\n",
    "    data.loc[:, '3P%'] = data.loc[:, '3P%'].fillna(0)\n",
    "    data = data.drop_duplicates()\n",
    "    \n",
    "    if method == 'oversample':\n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        X = data.drop('TARGET_5Yrs', axis=1)\n",
    "        y = data['TARGET_5Yrs']\n",
    "        X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "        data = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "    elif method == 'undersample':\n",
    "        rus = RandomUnderSampler(random_state=0)\n",
    "        X = data.drop('TARGET_5Yrs', axis=1)\n",
    "        y = data['TARGET_5Yrs']\n",
    "        X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "        data = pd.concat([X_resampled, y_resampled], axis=1).reset_index(drop=True)\n",
    "    elif method == 'smote':\n",
    "        sm = SMOTE(random_state=0)\n",
    "        X = data.drop('TARGET_5Yrs', axis=1)\n",
    "        y = data['TARGET_5Yrs']\n",
    "        X_resampled, y_resampled = sm.fit_resample(X, y)\n",
    "        data = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def score_classifier(dataset,classifier,labels, folds=3, verbose=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes in a dataset, classifier and labels and returns the mean confusion matrix, recall, precision, accuracy and f1 score\n",
    "    for the classifier using KFold cross validation with the number of folds specified by the user\n",
    "\n",
    "    Parameters:\n",
    "    dataset: pandas dataframe\n",
    "    classifier: sklearn classifier\n",
    "    labels: pandas series\n",
    "    folds: int\n",
    "\n",
    "    Returns:\n",
    "    dict: dictionary containing mean confusion matrix, recall, precision, accuracy and f1 score\n",
    "    \"\"\"\n",
    "\n",
    "    kf = KFold(n_splits=folds,random_state=50,shuffle=True)\n",
    "    confusion_mat_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    accuracy_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for training_ids,test_ids in kf.split(dataset):\n",
    "        training_set = dataset.iloc[training_ids]\n",
    "        training_labels = labels.iloc[training_ids]\n",
    "        test_set = dataset.iloc[test_ids]\n",
    "        test_labels = labels.iloc[test_ids]\n",
    "        classifier.fit(training_set,training_labels)\n",
    "        predicted_labels = classifier.predict(test_set)\n",
    "\n",
    "        confusion_mat = confusion_matrix(test_labels,predicted_labels)\n",
    "        recall = recall_score(test_labels, predicted_labels)\n",
    "        precision = precision_score(test_labels, predicted_labels)\n",
    "        accuracy = classifier.score(test_set, test_labels)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n",
    "        accuracy_list.append(accuracy)\n",
    "        f1_list.append(f1)\n",
    "        confusion_mat_list.append(confusion_mat)\n",
    "\n",
    "    recall = np.mean(recall_list)\n",
    "    precision = np.mean(precision_list)\n",
    "    accuracy = np.mean(accuracy_list)\n",
    "    f1 = np.mean(f1_list)\n",
    "    confusion_mat = np.mean(confusion_mat_list,axis=0).astype(int)\n",
    "    confusion_mat_df = pd.DataFrame(confusion_mat,columns=['Predicted 0','Predicted 1'],index=['Actual 0','Actual 1'])\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"confusion_mat: \\n {confusion_mat_df}\")\n",
    "        print(f\"recall:{recall}\")\n",
    "        print(f\"precision:{precision}\")\n",
    "        print(f\"accuracy:{accuracy}\")\n",
    "        print(f\"f1:{f1}\")\n",
    "    return {'confusion_mat':confusion_mat,'recall':recall,'precision':precision,'accuracy':accuracy,'f1':f1, 'classifier':classifier}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_mat: \n",
      "           Predicted 0  Predicted 1\n",
      "Actual 0           52           49\n",
      "Actual 1           28          137\n",
      "recall:0.8283688155659495\n",
      "precision:0.737618408158071\n",
      "accuracy:0.7104477611940297\n",
      "f1:0.7795266617095927\n"
     ]
    }
   ],
   "source": [
    "# first scores\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "df_test = df.copy()\n",
    "X = df_test.drop(['TARGET_5Yrs', 'Name'], axis=1)\n",
    "y = df_test['TARGET_5Yrs']\n",
    "\n",
    "# fill nan\n",
    "X.loc[:, '3P%'] = X.loc[:, '3P%'].fillna(0)\n",
    "\n",
    "pipeline = Pipeline(steps=[('scaler', MinMaxScaler()), ('classifier', SVC())])\n",
    "\n",
    "scores = score_classifier(X, pipeline, y, folds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion_mat</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>classifier</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[69, 57], [35, 170]]</td>\n",
       "      <td>0.827512</td>\n",
       "      <td>0.749402</td>\n",
       "      <td>0.721386</td>\n",
       "      <td>0.786348</td>\n",
       "      <td>(StandardScaler(), SVC())</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[66, 59], [37, 168]]</td>\n",
       "      <td>0.817619</td>\n",
       "      <td>0.738949</td>\n",
       "      <td>0.707831</td>\n",
       "      <td>0.776090</td>\n",
       "      <td>(StandardScaler(), LogisticRegression())</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[66, 59], [40, 165]]</td>\n",
       "      <td>0.803144</td>\n",
       "      <td>0.735562</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>0.767675</td>\n",
       "      <td>(StandardScaler(), ([DecisionTreeRegressor(cri...</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[66, 60], [43, 162]]</td>\n",
       "      <td>0.789960</td>\n",
       "      <td>0.730966</td>\n",
       "      <td>0.689006</td>\n",
       "      <td>0.759102</td>\n",
       "      <td>(StandardScaler(), (DecisionTreeClassifier(max...</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[67, 58], [47, 158]]</td>\n",
       "      <td>0.769095</td>\n",
       "      <td>0.731328</td>\n",
       "      <td>0.681476</td>\n",
       "      <td>0.749652</td>\n",
       "      <td>(StandardScaler(), (DecisionTreeClassifier(max...</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[65, 60], [46, 159]]</td>\n",
       "      <td>0.775847</td>\n",
       "      <td>0.725193</td>\n",
       "      <td>0.677711</td>\n",
       "      <td>0.749401</td>\n",
       "      <td>(StandardScaler(), KNeighborsClassifier())</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[64, 61], [51, 154]]</td>\n",
       "      <td>0.748303</td>\n",
       "      <td>0.714506</td>\n",
       "      <td>0.658886</td>\n",
       "      <td>0.730861</td>\n",
       "      <td>(StandardScaler(), XGBClassifier(base_score=No...</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[65, 60], [69, 136]]</td>\n",
       "      <td>0.663871</td>\n",
       "      <td>0.692213</td>\n",
       "      <td>0.608434</td>\n",
       "      <td>0.677678</td>\n",
       "      <td>(StandardScaler(), DecisionTreeClassifier())</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           confusion_mat    recall  precision  accuracy        f1  \\\n",
       "0  [[69, 57], [35, 170]]  0.827512   0.749402  0.721386  0.786348   \n",
       "1  [[66, 59], [37, 168]]  0.817619   0.738949  0.707831  0.776090   \n",
       "2  [[66, 59], [40, 165]]  0.803144   0.735562  0.698795  0.767675   \n",
       "3  [[66, 60], [43, 162]]  0.789960   0.730966  0.689006  0.759102   \n",
       "4  [[67, 58], [47, 158]]  0.769095   0.731328  0.681476  0.749652   \n",
       "5  [[65, 60], [46, 159]]  0.775847   0.725193  0.677711  0.749401   \n",
       "6  [[64, 61], [51, 154]]  0.748303   0.714506  0.658886  0.730861   \n",
       "7  [[65, 60], [69, 136]]  0.663871   0.692213  0.608434  0.677678   \n",
       "\n",
       "                                          classifier  \\\n",
       "0                          (StandardScaler(), SVC())   \n",
       "1           (StandardScaler(), LogisticRegression())   \n",
       "2  (StandardScaler(), ([DecisionTreeRegressor(cri...   \n",
       "3  (StandardScaler(), (DecisionTreeClassifier(max...   \n",
       "4  (StandardScaler(), (DecisionTreeClassifier(max...   \n",
       "5         (StandardScaler(), KNeighborsClassifier())   \n",
       "6  (StandardScaler(), XGBClassifier(base_score=No...   \n",
       "7       (StandardScaler(), DecisionTreeClassifier())   \n",
       "\n",
       "                   model_name  \n",
       "0                         SVC  \n",
       "1          LogisticRegression  \n",
       "2  GradientBoostingClassifier  \n",
       "3      RandomForestClassifier  \n",
       "4          AdaBoostClassifier  \n",
       "5        KNeighborsClassifier  \n",
       "6               XGBClassifier  \n",
       "7      DecisionTreeClassifier  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model search\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "target = 'TARGET_5Yrs'\n",
    "balance_method = None\n",
    "\n",
    "data_processed = preprocessing(df, balance_method)\n",
    "models = [LogisticRegression(), RandomForestClassifier(), SVC(), GradientBoostingClassifier(), KNeighborsClassifier(), DecisionTreeClassifier(), AdaBoostClassifier(), XGBClassifier()]\n",
    "model_names = ['LogisticRegression', 'RandomForestClassifier', 'SVC', 'GradientBoostingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'AdaBoostClassifier', 'XGBClassifier']\n",
    "\n",
    "results = []\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('model', model)])\n",
    "    result = score_classifier(data_processed.drop(target, axis=1), pipeline, data_processed[target], folds=4, verbose=False)\n",
    "    result['model_name'] = model_name\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='f1', ascending=False)\n",
    "results_df = results_df.reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion_mat</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>classifier</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[69, 56], [39, 166]]</td>\n",
       "      <td>0.807032</td>\n",
       "      <td>0.745591</td>\n",
       "      <td>0.709337</td>\n",
       "      <td>0.774982</td>\n",
       "      <td>(StandardScaler(), SVC())</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[67, 58], [39, 166]]</td>\n",
       "      <td>0.809057</td>\n",
       "      <td>0.740802</td>\n",
       "      <td>0.705572</td>\n",
       "      <td>0.772818</td>\n",
       "      <td>(StandardScaler(), LogisticRegression())</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[69, 56], [42, 164]]</td>\n",
       "      <td>0.795662</td>\n",
       "      <td>0.743451</td>\n",
       "      <td>0.703313</td>\n",
       "      <td>0.768308</td>\n",
       "      <td>(StandardScaler(), ([DecisionTreeRegressor(cri...</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[69, 56], [47, 158]]</td>\n",
       "      <td>0.769447</td>\n",
       "      <td>0.737294</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.752785</td>\n",
       "      <td>(StandardScaler(), (DecisionTreeClassifier(max...</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[66, 59], [45, 160]]</td>\n",
       "      <td>0.777813</td>\n",
       "      <td>0.729946</td>\n",
       "      <td>0.683735</td>\n",
       "      <td>0.752778</td>\n",
       "      <td>(StandardScaler(), (DecisionTreeClassifier(max...</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[64, 62], [50, 155]]</td>\n",
       "      <td>0.755328</td>\n",
       "      <td>0.714996</td>\n",
       "      <td>0.661898</td>\n",
       "      <td>0.734181</td>\n",
       "      <td>(StandardScaler(), KNeighborsClassifier())</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[63, 62], [51, 154]]</td>\n",
       "      <td>0.748388</td>\n",
       "      <td>0.710106</td>\n",
       "      <td>0.655120</td>\n",
       "      <td>0.728496</td>\n",
       "      <td>(StandardScaler(), XGBClassifier(base_score=No...</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[63, 62], [69, 136]]</td>\n",
       "      <td>0.662225</td>\n",
       "      <td>0.686507</td>\n",
       "      <td>0.603163</td>\n",
       "      <td>0.674089</td>\n",
       "      <td>(StandardScaler(), DecisionTreeClassifier())</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           confusion_mat    recall  precision  accuracy        f1  \\\n",
       "0  [[69, 56], [39, 166]]  0.807032   0.745591  0.709337  0.774982   \n",
       "1  [[67, 58], [39, 166]]  0.809057   0.740802  0.705572  0.772818   \n",
       "2  [[69, 56], [42, 164]]  0.795662   0.743451  0.703313  0.768308   \n",
       "3  [[69, 56], [47, 158]]  0.769447   0.737294  0.686747  0.752785   \n",
       "4  [[66, 59], [45, 160]]  0.777813   0.729946  0.683735  0.752778   \n",
       "5  [[64, 62], [50, 155]]  0.755328   0.714996  0.661898  0.734181   \n",
       "6  [[63, 62], [51, 154]]  0.748388   0.710106  0.655120  0.728496   \n",
       "7  [[63, 62], [69, 136]]  0.662225   0.686507  0.603163  0.674089   \n",
       "\n",
       "                                          classifier  \\\n",
       "0                          (StandardScaler(), SVC())   \n",
       "1           (StandardScaler(), LogisticRegression())   \n",
       "2  (StandardScaler(), ([DecisionTreeRegressor(cri...   \n",
       "3  (StandardScaler(), (DecisionTreeClassifier(max...   \n",
       "4  (StandardScaler(), (DecisionTreeClassifier(max...   \n",
       "5         (StandardScaler(), KNeighborsClassifier())   \n",
       "6  (StandardScaler(), XGBClassifier(base_score=No...   \n",
       "7       (StandardScaler(), DecisionTreeClassifier())   \n",
       "\n",
       "                   model_name  \n",
       "0                         SVC  \n",
       "1          LogisticRegression  \n",
       "2  GradientBoostingClassifier  \n",
       "3          AdaBoostClassifier  \n",
       "4      RandomForestClassifier  \n",
       "5        KNeighborsClassifier  \n",
       "6               XGBClassifier  \n",
       "7      DecisionTreeClassifier  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model search - feature selection\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "target = 'TARGET_5Yrs'\n",
    "balance_method = None\n",
    "features_selected = ['GP', 'PTS', 'FGM', 'MIN', 'FTA', 'FTM', 'REB', 'OREB', 'FGA']\n",
    "\n",
    "data_processed = preprocessing(df, balance_method)\n",
    "X = data_processed[features_selected]\n",
    "y = data_processed[target]\n",
    "\n",
    "models = [LogisticRegression(), RandomForestClassifier(), SVC(), GradientBoostingClassifier(), KNeighborsClassifier(), DecisionTreeClassifier(), AdaBoostClassifier(), XGBClassifier()]\n",
    "model_names = ['LogisticRegression', 'RandomForestClassifier', 'SVC', 'GradientBoostingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'AdaBoostClassifier', 'XGBClassifier']\n",
    "\n",
    "results = []\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('model', model)])\n",
    "    result = score_classifier(X, pipeline, y, folds=4, verbose=False)\n",
    "    result['model_name'] = model_name\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='f1', ascending=False)\n",
    "results_df = results_df.reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion_mat</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>classifier</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[43, 57], [21, 143]]</td>\n",
       "      <td>0.871370</td>\n",
       "      <td>0.716554</td>\n",
       "      <td>0.705555</td>\n",
       "      <td>0.785391</td>\n",
       "      <td>(LogisticRegression(C=0.1, solver='liblinear'))</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[55, 45], [30, 134]]</td>\n",
       "      <td>0.814348</td>\n",
       "      <td>0.747913</td>\n",
       "      <td>0.714592</td>\n",
       "      <td>0.779292</td>\n",
       "      <td>(StandardScaler(), SVC())</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           confusion_mat    recall  precision  accuracy        f1  \\\n",
       "0  [[43, 57], [21, 143]]  0.871370   0.716554  0.705555  0.785391   \n",
       "1  [[55, 45], [30, 134]]  0.814348   0.747913  0.714592  0.779292   \n",
       "\n",
       "                                        classifier          model_name  \n",
       "0  (LogisticRegression(C=0.1, solver='liblinear'))  LogisticRegression  \n",
       "1                        (StandardScaler(), SVC())                 SVC  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model search - feature selection\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "target = 'TARGET_5Yrs'\n",
    "balance_method = None\n",
    "features_selected = ['GP', 'PTS', 'FGM', 'MIN', 'FTA', 'FTM', 'REB', 'OREB', 'FGA']\n",
    "\n",
    "data_processed = preprocessing(df, balance_method)\n",
    "X = data_processed[features_selected]\n",
    "y = data_processed[target]\n",
    "\n",
    "lr = Pipeline(steps=[('model', LogisticRegression(C=0.1, solver='liblinear'))])\n",
    "svc = Pipeline(steps=[('scaler', StandardScaler()), ('model', SVC())])\n",
    "\n",
    "models = [lr, svc]\n",
    "model_names = ['LogisticRegression', 'SVC']\n",
    "\n",
    "results = []\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    result = score_classifier(X, model, y, folds=5, verbose=False)\n",
    "    result['model_name'] = model_name\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='f1', ascending=False)\n",
    "results_df = results_df.reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion_mat</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>classifier</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[36, 64], [19, 145]]</td>\n",
       "      <td>0.883783</td>\n",
       "      <td>0.692918</td>\n",
       "      <td>0.685206</td>\n",
       "      <td>0.776392</td>\n",
       "      <td>(LogisticRegression(C=0.1, solver='liblinear'))</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[49, 51], [34, 130]]</td>\n",
       "      <td>0.793900</td>\n",
       "      <td>0.719427</td>\n",
       "      <td>0.679200</td>\n",
       "      <td>0.754018</td>\n",
       "      <td>(StandardScaler(), SVC())</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           confusion_mat    recall  precision  accuracy        f1  \\\n",
       "0  [[36, 64], [19, 145]]  0.883783   0.692918  0.685206  0.776392   \n",
       "1  [[49, 51], [34, 130]]  0.793900   0.719427  0.679200  0.754018   \n",
       "\n",
       "                                        classifier          model_name  \n",
       "0  (LogisticRegression(C=0.1, solver='liblinear'))  LogisticRegression  \n",
       "1                        (StandardScaler(), SVC())                 SVC  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'TARGET_5Yrs'\n",
    "balance_method = None\n",
    "features_selected = ['GP']\n",
    "\n",
    "data_processed = preprocessing(df, balance_method)\n",
    "X = data_processed[features_selected]\n",
    "y = data_processed[target]\n",
    "\n",
    "lr = Pipeline(steps=[('model', LogisticRegression(C=0.1, solver='liblinear'))])\n",
    "svc = Pipeline(steps=[('scaler', StandardScaler()), ('model', SVC())])\n",
    "\n",
    "models = [lr, svc]\n",
    "model_names = ['LogisticRegression', 'SVC']\n",
    "\n",
    "results = []\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    result = score_classifier(X, model, y, folds=5, verbose=False)\n",
    "    result['model_name'] = model_name\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='f1', ascending=False)\n",
    "results_df = results_df.reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confusion_mat</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>classifier</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[43, 57], [21, 143]]</td>\n",
       "      <td>0.871370</td>\n",
       "      <td>0.716554</td>\n",
       "      <td>0.705555</td>\n",
       "      <td>0.785391</td>\n",
       "      <td>(LogisticRegression(C=0.1, solver='liblinear'))</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[55, 45], [30, 134]]</td>\n",
       "      <td>0.814348</td>\n",
       "      <td>0.747913</td>\n",
       "      <td>0.714592</td>\n",
       "      <td>0.779292</td>\n",
       "      <td>(StandardScaler(), SVC())</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           confusion_mat    recall  precision  accuracy        f1  \\\n",
       "0  [[43, 57], [21, 143]]  0.871370   0.716554  0.705555  0.785391   \n",
       "1  [[55, 45], [30, 134]]  0.814348   0.747913  0.714592  0.779292   \n",
       "\n",
       "                                        classifier          model_name  \n",
       "0  (LogisticRegression(C=0.1, solver='liblinear'))  LogisticRegression  \n",
       "1                        (StandardScaler(), SVC())                 SVC  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'TARGET_5Yrs'\n",
    "balance_method = None\n",
    "features_selected = ['GP', 'PTS', 'FGM', 'MIN', 'FTA', 'FTM', 'REB', 'OREB', 'FGA']\n",
    "data_processed = preprocessing(df, balance_method)\n",
    "X = data_processed[features_selected]\n",
    "y = data_processed[target]\n",
    "\n",
    "lr = Pipeline(steps=[('model', LogisticRegression(C=0.1, solver='liblinear'))])\n",
    "svc = Pipeline(steps=[('scaler', StandardScaler()), ('model', SVC())])\n",
    "\n",
    "models = [lr, svc]\n",
    "model_names = ['LogisticRegression', 'SVC']\n",
    "\n",
    "results = []\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    result = score_classifier(X, model, y, folds=5, verbose=False)\n",
    "    result['model_name'] = model_name\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='f1', ascending=False)\n",
    "results_df = results_df.reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'select_k_best__k': 12, 'polynomial_features__degree': 1, 'model__solver': 'liblinear', 'model__C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "target = 'TARGET_5Yrs'\n",
    "balance_method = None\n",
    "\n",
    "data_processed = preprocessing(df, balance_method)\n",
    "X = data_processed.drop(target, axis=1)\n",
    "y = data_processed[target]\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('polynomial_features', PolynomialFeatures(2, include_bias=False)), \n",
    "    ('select_k_best', SelectKBest(f_classif, k=10)), \n",
    "    ('model', LogisticRegression())])\n",
    "\n",
    "param_grid = {'polynomial_features__degree': range(1, 5),\n",
    "                'select_k_best__k': range(1, 19),\n",
    "                'model__C': [0.01, 0.1, 1, 10],\n",
    "                'model__solver': ['liblinear', 'lbfgs', 'saga']}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1, n_iter=100)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'select_k_best__k': 9, 'polynomial_features__degree': 1, 'model__solver': 'liblinear', 'model__C': 0.12}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "target = 'TARGET_5Yrs'\n",
    "balance_method = None\n",
    "\n",
    "data_processed = preprocessing(df, balance_method)\n",
    "X = data_processed.drop(target, axis=1)\n",
    "y = data_processed[target]\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('polynomial_features', PolynomialFeatures(2, include_bias=False)), \n",
    "    ('select_k_best', SelectKBest(f_classif, k=10)), \n",
    "    ('model', LogisticRegression())])\n",
    "\n",
    "param_grid = {'polynomial_features__degree': range(1, 3),\n",
    "                'select_k_best__k': range(1, 19),\n",
    "                'model__C': [0.08, 0.1, 0.12],\n",
    "                'model__solver': ['liblinear']}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1, n_iter=100)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confusion_mat': array([[ 43,  57],\n",
       "        [ 21, 143]]),\n",
       " 'recall': 0.8679412336549746,\n",
       " 'precision': 0.7136693268472322,\n",
       " 'accuracy': 0.7010441197332955,\n",
       " 'f1': 0.7822574483137785,\n",
       " 'classifier': Pipeline(steps=[('polynomial_features',\n",
       "                  PolynomialFeatures(degree=1, include_bias=False)),\n",
       "                 ('select_k_best', SelectKBest(k=9)),\n",
       "                 ('model', LogisticRegression(C=0.1, solver='liblinear'))]),\n",
       " 'model_name': 'LogisticRegression'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'TARGET_5Yrs'\n",
    "balance_method = None\n",
    "\n",
    "data_processed = preprocessing(df, balance_method)\n",
    "X = data_processed.drop(target, axis=1)\n",
    "y = data_processed[target]\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('polynomial_features', PolynomialFeatures(1, include_bias=False)), \n",
    "    ('select_k_best', SelectKBest(f_classif, k=9)), \n",
    "    ('model', LogisticRegression(C=0.1, solver='liblinear'))])\n",
    "\n",
    "result = score_classifier(X, pipeline, y, folds=5, verbose=False)\n",
    "result['model_name'] = 'LogisticRegression'\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'select_k_best__k': 17, 'polynomial_features__degree': 1, 'model__kernel': 'poly', 'model__gamma': 'scale', 'model__C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "target = 'TARGET_5Yrs'\n",
    "balance_method = None\n",
    "\n",
    "data_processed = preprocessing(df, balance_method)\n",
    "X = data_processed.drop(target, axis=1)\n",
    "y = data_processed[target]\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('polynomial_features', PolynomialFeatures(2, include_bias=False)), \n",
    "    ('select_k_best', SelectKBest(f_classif, k=10)), \n",
    "    ('model', SVC())])\n",
    "\n",
    "param_grid = {'polynomial_features__degree': range(1, 3),\n",
    "                'select_k_best__k': range(1, 19),\n",
    "                'model__C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "                'model__kernel': ['poly'],\n",
    "                'model__gamma': ['scale']}\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1, n_iter=100)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confusion_mat': array([[ 47,  53],\n",
       "        [ 25, 139]]),\n",
       " 'recall': 0.8470344173344924,\n",
       " 'precision': 0.7218069000323044,\n",
       " 'accuracy': 0.702536530004256,\n",
       " 'f1': 0.7788139894283326,\n",
       " 'classifier': Pipeline(steps=[('polynomial_features',\n",
       "                  PolynomialFeatures(degree=1, include_bias=False)),\n",
       "                 ('select_k_best', SelectKBest(k=16)), ('model', SVC(C=1))]),\n",
       " 'model_name': 'LogisticRegression'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'TARGET_5Yrs'\n",
    "balance_method = None\n",
    "\n",
    "data_processed = preprocessing(df, balance_method)\n",
    "X = data_processed.drop(target, axis=1)\n",
    "y = data_processed[target]\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('polynomial_features', PolynomialFeatures(1, include_bias=False)), \n",
    "    ('select_k_best', SelectKBest(f_classif, k=16)), \n",
    "    ('model', SVC(C=1, kernel='rbf', gamma='scale'))])\n",
    "\n",
    "result = score_classifier(X, pipeline, y, folds=5, verbose=False)\n",
    "result['model_name'] = 'LogisticRegression'\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.43"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "target = 'TARGET_5Yrs'\n",
    "balance_method = None\n",
    "features_selected = ['GP', 'PTS', 'FGM', 'MIN', 'FTA', 'FTM', 'REB', 'OREB', 'FGA']\n",
    "\n",
    "data_processed = preprocessing(df, balance_method)\n",
    "X = data_processed[features_selected]\n",
    "y = data_processed[target]\n",
    "\n",
    "lr = Pipeline(steps=[('model', LogisticRegression(C=0.1, solver='liblinear'))])\n",
    "\n",
    "result = score_classifier(X, lr, y, folds=5, verbose=False)\n",
    "probabilities = lr.predict_proba(X)\n",
    "\n",
    "thresholds = np.arange(0, 1, 0.01)\n",
    "scores = []\n",
    "for threshold in thresholds:\n",
    "    predictions = probabilities[:, 1] > threshold\n",
    "    scores.append(f1_score(y, predictions))\n",
    "\n",
    "plt.plot(thresholds, scores)\n",
    "plt.show()\n",
    "\n",
    "thresholds[np.argmax(scores)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_threshold(model, X, threshold=0.43):\n",
    "    probabilities = model.predict_proba(X)\n",
    "    predictions = probabilities[:, 1] > threshold\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confusion_mat': array([[ 43,  57],\n",
       "        [ 21, 143]]),\n",
       " 'recall': 0.8713698050835461,\n",
       " 'precision': 0.7165539422318477,\n",
       " 'accuracy': 0.7055553979287843,\n",
       " 'f1': 0.785390607582708,\n",
       " 'classifier': Pipeline(steps=[('model', LogisticRegression(C=0.1, solver='liblinear'))])}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final model performance\n",
    "\n",
    "target = 'TARGET_5Yrs'\n",
    "balance_method = None\n",
    "features_selected = ['GP', 'PTS', 'FGM', 'MIN', 'FTA', 'FTM', 'REB', 'OREB', 'FGA']\n",
    "\n",
    "data_processed = preprocessing(df, balance_method)\n",
    "X = data_processed[features_selected]\n",
    "y = data_processed[target]\n",
    "\n",
    "lr = Pipeline(steps=[('model', LogisticRegression(C=0.1, solver='liblinear'))])\n",
    "\n",
    "result = score_classifier(X, lr, y, folds=5, verbose=False)\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "import joblib\n",
    "\n",
    "target = 'TARGET_5Yrs'\n",
    "balance_method = None\n",
    "features_selected = ['GP', 'PTS', 'FGM', 'MIN', 'FTA', 'FTM', 'REB', 'OREB', 'FGA']\n",
    "\n",
    "data_processed = preprocessing(df, balance_method)\n",
    "X = data_processed[features_selected]\n",
    "y = data_processed[target]\n",
    "\n",
    "lr = Pipeline(steps=[('model', LogisticRegression(C=0.1, solver='liblinear'))])\n",
    "lr.fit(X, y)\n",
    "\n",
    "joblib.dump(lr, './../models/model_1.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
